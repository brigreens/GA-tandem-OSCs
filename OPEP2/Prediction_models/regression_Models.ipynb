{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5774fd4-07ed-43d5-aa3c-cc74ed89d50c",
   "metadata": {},
   "source": [
    "# Models to predict PCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f02d5a54-a105-4e15-8238-e43c056d65f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "import seaborn as sns\n",
    "import math\n",
    "import statistics\n",
    "from scipy.stats import sem\n",
    "from scipy import stats\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from xgboost import XGBRFRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "import sklearn\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.utils import check_consistent_length\n",
    "from sklearn.utils import check_array\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, cross_val_predict\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import math\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd8528d9-fa39-4ddc-9c1f-68369de68c39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of donor-acceptor pairs is: 999\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('descriptors_with_fingerprints.csv')\n",
    "print('Number of donor-acceptor pairs is: ' + str(len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "038c7d42-de85-4e4f-b599-3ff3254f5d15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of donor-acceptor pairs with a PCE greater than 10% is: 503\n"
     ]
    }
   ],
   "source": [
    "data_highPCE = data[data['PCE'] > 10]\n",
    "print('Number of donor-acceptor pairs with a PCE greater than 10% is: ' + str(len(data_highPCE)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "360d073e-552f-458e-a864-706f768e2a50",
   "metadata": {},
   "source": [
    "## LASSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eb17276b-e235-4242-a3fc-7e41dd19d762",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Will tune the descriptors down to 6 until to achieve an optimized RMSE\n",
    "# returns a list of the top 6 descriptors\n",
    "def optimize_eq(df, target):\n",
    "    \n",
    "    all_descriptors = ['A-HOMO', 'A-HOMOminus1', 'A-LUMO', 'A-LUMOplus1', 'A-fundbg', 'A-deltaHOMO', 'A-deltaLUMO', 'A-opt_bg', 'A-max_abs', 'A-summed_oscs', 'A-area_spectra', 'A-area_sim_solar_spectra', 'A-chemical_potential', 'A-electrophilicity', 'A-pi_sys_size', 'A-num_rot_bonds', 'A-MolLogP', 'A-TPSA', 'A-NumHAcceptors', 'A-NumHDonors', 'A-RingCount', 'A-planarity','A-dipole_moment', 'A-polarizability', 'A-SolvationEnergy_water', 'A-SolvationEnergy_hexane', 'D-HOMO', 'D-HOMOminus1', 'D-LUMO', 'D-LUMOplus1', 'D-fundbg', 'D-deltaHOMO', 'D-deltaLUMO', 'D-opt_bg', 'D-max_abs', 'D-summed_oscs', 'D-area_spectra', 'D-area_sim_solar_spectra', 'D-chemical_potential', 'D-electrophilicity', 'D-pi_sys_size', 'D-num_rot_bonds', 'D-MolLogP', 'D-TPSA', 'D-NumHAcceptors', 'D-NumHDonors', 'D-RingCount', 'D-planarity','D-dipole_moment', 'D-polarizability', 'D-SolvationEnergy_water', 'D-SolvationEnergy_hexane', 'AD-overlap', 'AD-HOMOoffset', 'AD-LUMOoffset', 'DHOMO_ALUMO_offset']\n",
    "    \n",
    "    # LASSO to remove any with coefficients of zero\n",
    "    descriptors_to_remove = []\n",
    "    results = evaluate_model(all_descriptors, df[target], df,output=False)\n",
    "    for x in range(len(results[9])):\n",
    "        if results[9][x][1] == 0.0:\n",
    "            descriptors_to_remove.append(results[9][x][0])\n",
    "            \n",
    "    for x in descriptors_to_remove:\n",
    "        all_descriptors.remove(x)\n",
    "    print(all_descriptors)\n",
    "    \n",
    "    while len(all_descriptors) > 8:\n",
    "        rmse = 100.0\n",
    "        diff = 0.0\n",
    "        mae = 100.0\n",
    "        r2 = -1.00\n",
    "        for x in range(len(all_descriptors)):\n",
    "            temp_descriptor = all_descriptors[x]\n",
    "            new_list = all_descriptors.copy()\n",
    "            new_list.remove(temp_descriptor)\n",
    "            results = evaluate_model(new_list, df[target], df,output=False)\n",
    "            new_diff = 100.0 - float(results[4])\n",
    "            \n",
    "            if new_diff >= diff:\n",
    "                if new_diff == diff:\n",
    "                    if mae == results[2]:\n",
    "                        if results[0] > r2:\n",
    "                            diff = new_diff\n",
    "                            mae = results[2]\n",
    "                            r2 = results[0]\n",
    "                            rmse = results[4]\n",
    "                            best_list = new_list\n",
    "                    elif mae > results[2]:\n",
    "                        diff = new_diff\n",
    "                        mae = results[2]\n",
    "                        r2 = results[0]\n",
    "                        rmse = results[4]\n",
    "                        best_list = new_list\n",
    "                else:\n",
    "                    diff = new_diff\n",
    "                    mae = results[2]\n",
    "                    r2 = results[0]\n",
    "                    rmse = results[4]\n",
    "                    best_list = new_list\n",
    "                \n",
    "        all_descriptors = best_list\n",
    "        print(len(all_descriptors))\n",
    "        print(rmse)\n",
    "        \n",
    "    print(all_descriptors)\n",
    "    print(rmse)\n",
    "    \n",
    "    return all_descriptors\n",
    "\n",
    "## from sci-kit-learn https://github.com/scikit-learn/scikit-learn/blob/4773f3e39/sklearn/metrics/_regression.py#L197\n",
    "def _check_reg_targets(y_true, y_pred, multioutput, dtype=\"numeric\"):\n",
    "    check_consistent_length(y_true, y_pred)\n",
    "    y_true = check_array(y_true, ensure_2d=False, dtype=dtype)\n",
    "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
    "\n",
    "    if y_true.ndim == 1:\n",
    "        y_true = y_true.reshape((-1, 1))\n",
    "\n",
    "    if y_pred.ndim == 1:\n",
    "        y_pred = y_pred.reshape((-1, 1))\n",
    "\n",
    "    if y_true.shape[1] != y_pred.shape[1]:\n",
    "        raise ValueError(\"y_true and y_pred have different number of output \"\n",
    "                         \"({0}!={1})\".format(y_true.shape[1], y_pred.shape[1]))\n",
    "\n",
    "    n_outputs = y_true.shape[1]\n",
    "    allowed_multioutput_str = ('raw_values', 'uniform_average',\n",
    "                               'variance_weighted')\n",
    "    if isinstance(multioutput, str):\n",
    "        if multioutput not in allowed_multioutput_str:\n",
    "            raise ValueError(\"Allowed 'multioutput' string values are {}. \"\n",
    "                             \"You provided multioutput={!r}\".format(\n",
    "                                 allowed_multioutput_str,\n",
    "                                 multioutput))\n",
    "    elif multioutput is not None:\n",
    "        multioutput = check_array(multioutput, ensure_2d=False)\n",
    "        if n_outputs == 1:\n",
    "            raise ValueError(\"Custom weights are useful only in \"\n",
    "                             \"multi-output cases.\")\n",
    "        elif n_outputs != len(multioutput):\n",
    "            raise ValueError((\"There must be equally many custom weights \"\n",
    "                              \"(%d) as outputs (%d).\") %\n",
    "                             (len(multioutput), n_outputs))\n",
    "    y_type = 'continuous' if n_outputs == 1 else 'continuous-multioutput'\n",
    "\n",
    "    return y_type, y_true, y_pred, multioutput\n",
    "\n",
    "def mean_absolute_percentage_error(y_true, y_pred,\n",
    "                                   sample_weight=None,\n",
    "                                   multioutput='uniform_average'):\n",
    "\n",
    "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
    "        y_true, y_pred, multioutput)\n",
    "    check_consistent_length(y_true, y_pred, sample_weight)\n",
    "    epsilon = np.finfo(np.float64).eps\n",
    "    mape = np.abs(y_pred - y_true) / np.maximum(np.abs(y_true), epsilon)\n",
    "    output_errors = np.average(mape,\n",
    "                               weights=sample_weight, axis=0)\n",
    "    if isinstance(multioutput, str):\n",
    "        if multioutput == 'raw_values':\n",
    "            return output_errors\n",
    "        elif multioutput == 'uniform_average':\n",
    "            # pass None as weights to np.average: uniform mean\n",
    "            multioutput = None\n",
    "\n",
    "    return np.average(output_errors, weights=multioutput)\n",
    "\n",
    "def evaluate_model(list_of_desc, target, dataframe, cf = False, output=True):\n",
    "    '''\n",
    "    Evaluates the errors of the proposed model\n",
    "    \n",
    "    Parameters\n",
    "    ---------\n",
    "    list_of_desc = name of the list that contains the descriptors\n",
    "    target = target experimental value in the dataframe. Ex: df_highPCE['ExperimentalJsc']\n",
    "    dataframe = name of dataframe to use descriptors from\n",
    "    cf = should it show the coefficients\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    R2, MAE, RMSE, MAPE, y-intercept of equation, coefficients of each descriptor, average predictions\n",
    "    '''\n",
    "    \n",
    "    new_df = dataframe[list_of_desc].copy()\n",
    "    \n",
    "    max_mae = 10.0\n",
    "    best_alpha = 0\n",
    "    for a in range(1,200):\n",
    "        lm =Lasso(alpha=float(a)/100.0)\n",
    "        lm.fit(new_df, target)\n",
    "        mae = mean_absolute_error(target, lm.predict(new_df))\n",
    "        if mae < max_mae:\n",
    "            best_alpha = float(a)/100.0\n",
    "            max_mae = mae\n",
    "\n",
    "    r2_score = []\n",
    "    intercepts = []\n",
    "    coefs = []\n",
    "    predicted_PCE = []\n",
    "    MAE_cv = []\n",
    "    RMSE_cv = []\n",
    "    \n",
    "    print('Best alpha is', best_alpha)\n",
    "\n",
    "    PCE_cv = cross_validate(Lasso(alpha = best_alpha, max_iter = 100000), new_df, target, cv=5, scoring = ['neg_mean_squared_error'] , return_estimator = True)\n",
    "    for x in PCE_cv['estimator']:\n",
    "        coef = x.coef_\n",
    "        coefs.append(coef)\n",
    "\n",
    "        pred = x.predict(new_df)\n",
    "        predicted_PCE.append(pred)\n",
    "\n",
    "        r2_score.append(x.score(new_df, target))\n",
    "        intercepts.append(x.intercept_)\n",
    "\n",
    "        \n",
    "    avg_coef = sum(coefs)/5.0    \n",
    "    zipped_coefs = zip(list_of_desc, avg_coef)\n",
    "    \n",
    "    if output == True:\n",
    "        if cf == True:\n",
    "            print('The average intercept from 5 folds is ', statistics.mean(intercepts))\n",
    "            print('The average coefficients of the 5 folds is ', list(zipped_coefs))\n",
    "    \n",
    "    coefficients = list(zipped_coefs)\n",
    "    \n",
    "    avg_pred = sum(predicted_PCE)/ 5.0    \n",
    "    all_mae = []\n",
    "    all_RMSE = []\n",
    "    all_MAPE = []\n",
    "    for x in range(len(predicted_PCE)):\n",
    "        mae = mean_absolute_error(target, predicted_PCE[x])\n",
    "        all_mae.append(mae)\n",
    "        mse = mean_squared_error(target, predicted_PCE[x])\n",
    "        rmse = math.sqrt(mse)\n",
    "        all_RMSE.append(rmse)\n",
    "        mape = mean_absolute_percentage_error(target, predicted_PCE[x]) * 100\n",
    "        all_MAPE.append(mape)\n",
    "    SEM_mae = round(sem(all_mae), 3)\n",
    "    SEM_RMSE = round(sem(all_RMSE), 5)\n",
    "    SEM_MAPE = round(sem(all_MAPE), 5)\n",
    "    \n",
    "    \n",
    "    mean_MAE = round(statistics.mean(all_mae), 3)\n",
    "    mean_RMSE = round(statistics.mean(all_RMSE), 4)\n",
    "    mean_MAPE = round(statistics.mean(all_MAPE), 4)\n",
    "    SEM_r2 = round(sem(r2_score), 3)\n",
    "    \n",
    "    if output == True:\n",
    "        print('The 5-fold cross-validated RMSE of this model is, ', mean_RMSE, ' +/- ', SEM_RMSE)\n",
    "        print('The 5-fold cross-validated MAE of the average ', mean_MAE, ' +/- ', SEM_mae)\n",
    "        print('The average r^2 value is ', statistics.mean(r2_score), ' +/- ', SEM_r2 )\n",
    "    mean_r2 = round(statistics.mean(r2_score), 3)\n",
    "    \n",
    "    intercept = statistics.mean(intercepts)\n",
    "    \n",
    "    return mean_r2, SEM_r2, mean_MAE, SEM_mae, mean_RMSE, SEM_RMSE, mean_MAPE, SEM_MAPE, intercept, coefficients, avg_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "96bd6202-d561-4620-9b1f-1814dd294ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.programcreek.com/python/example/99249/sklearn.linear_model.LassoCV\n",
    "\n",
    "def load_default(self, machine_list='basic'):\n",
    "        \"\"\"\n",
    "        Loads 4 different scikit-learn regressors by default. The advanced list adds more machines. \n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        machine_list: optional, list of strings\n",
    "            List of default machine names to be loaded.\n",
    "        Returns\n",
    "        -------\n",
    "        self : returns an instance of self.\n",
    "        \"\"\"\n",
    "\n",
    "        if machine_list == 'basic':\n",
    "            machine_list = ['tree', 'ridge', 'random_forest', 'svm']\n",
    "        if machine_list == 'advanced':\n",
    "            machine_list=['lasso', 'tree', 'ridge', 'random_forest', 'svm', 'bayesian_ridge', 'sgd']\n",
    "\n",
    "        self.estimators_ = {}\n",
    "        for machine in machine_list:\n",
    "            try:\n",
    "                if machine == 'lasso':\n",
    "                    self.estimators_['lasso'] = linear_model.LassoCV(random_state=self.random_state).fit(self.X_k_, self.y_k_)\n",
    "                if machine == 'tree':\n",
    "                    self.estimators_['tree'] = DecisionTreeRegressor(random_state=self.random_state).fit(self.X_k_, self.y_k_)\n",
    "                if machine == 'ridge':\n",
    "                    self.estimators_['ridge'] = linear_model.RidgeCV().fit(self.X_k_, self.y_k_)\n",
    "                if machine == 'random_forest':\n",
    "                    self.estimators_['random_forest'] = RandomForestRegressor(random_state=self.random_state).fit(self.X_k_, self.y_k_)\n",
    "                if machine == 'svm':\n",
    "                    self.estimators_['svm'] = LinearSVR(random_state=self.random_state).fit(self.X_k_, self.y_k_)\n",
    "                if machine == 'sgd':\n",
    "                    self.estimators_['sgd'] = linear_model.SGDRegressor(random_state=self.random_state).fit(self.X_k_, self.y_k_)\n",
    "                if machine == 'bayesian_ridge':\n",
    "                    self.estimators_['bayesian_ridge'] = linear_model.BayesianRidge().fit(self.X_k_, self.y_k_)\n",
    "            except ValueError:\n",
    "                continue\n",
    "        return self "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ef9aab-208c-45ae-8181-8d4dc92c65aa",
   "metadata": {},
   "source": [
    "Lets see which descriptors LASSO selects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b988486c-4c33-4fbb-94b8-771049975242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 56 descriptors\n"
     ]
    }
   ],
   "source": [
    "all_descriptors = ['A-HOMO', 'A-HOMOminus1', 'A-LUMO', 'A-LUMOplus1', 'A-fundbg', 'A-deltaHOMO', 'A-deltaLUMO', 'A-opt_bg', 'A-max_abs', 'A-summed_oscs', 'A-area_spectra', 'A-area_sim_solar_spectra', 'A-chemical_potential', 'A-electrophilicity', 'A-pi_sys_size', 'A-num_rot_bonds', 'A-MolLogP', 'A-TPSA', 'A-NumHAcceptors', 'A-NumHDonors', 'A-RingCount', 'A-planarity','A-dipole_moment', 'A-polarizability', 'A-SolvationEnergy_water', 'A-SolvationEnergy_hexane', 'D-HOMO', 'D-HOMOminus1', 'D-LUMO', 'D-LUMOplus1', 'D-fundbg', 'D-deltaHOMO', 'D-deltaLUMO', 'D-opt_bg', 'D-max_abs', 'D-summed_oscs', 'D-area_spectra', 'D-area_sim_solar_spectra', 'D-chemical_potential', 'D-electrophilicity', 'D-pi_sys_size', 'D-num_rot_bonds', 'D-MolLogP', 'D-TPSA', 'D-NumHAcceptors', 'D-NumHDonors', 'D-RingCount', 'D-planarity','D-dipole_moment', 'D-polarizability', 'D-SolvationEnergy_water', 'D-SolvationEnergy_hexane', 'AD-overlap', 'AD-HOMOoffset', 'AD-LUMOoffset', 'DHOMO_ALUMO_offset']\n",
    "print(\"There are \" + str(len(all_descriptors)) + ' descriptors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3a5807b5-2d51-4095-b904-09b0322786ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha is 0.01\n",
      "The average intercept from 5 folds is  -47.38757239637007\n",
      "The average coefficients of the 5 folds is  [('A-HOMO', 0.0), ('A-HOMOminus1', 0.0), ('A-LUMO', -0.04882236075415286), ('A-LUMOplus1', -0.2015438690236909), ('A-fundbg', 0.0), ('A-deltaHOMO', -2.0170885567343686), ('A-deltaLUMO', -0.24370157033836576), ('A-opt_bg', -0.0005866894610065203), ('A-max_abs', 0.014867711507319609), ('A-summed_oscs', -0.17175346537976693), ('A-area_spectra', -0.0030290807766185012), ('A-area_sim_solar_spectra', 0.2051748545984285), ('A-chemical_potential', 0.0), ('A-electrophilicity', -0.025838391600273198), ('A-pi_sys_size', -0.04599825008037868), ('A-num_rot_bonds', -0.404151000414417), ('A-MolLogP', 0.337854734879463), ('A-TPSA', 0.021322106811522516), ('A-NumHAcceptors', 0.04879788506481016), ('A-NumHDonors', 0.0), ('A-RingCount', -0.0844654088687202), ('A-planarity', -0.38769472281142325), ('A-dipole_moment', -0.044170580476774114), ('A-polarizability', 0.000375179912725825), ('A-SolvationEnergy_water', 0.0), ('A-SolvationEnergy_hexane', 0.0), ('D-HOMO', 0.0), ('D-HOMOminus1', -2.0180239693440187), ('D-LUMO', 0.0), ('D-LUMOplus1', -2.3491080055577123), ('D-fundbg', 0.0), ('D-deltaHOMO', 0.0), ('D-deltaLUMO', 0.0), ('D-opt_bg', 0.0), ('D-max_abs', -0.0023307163171998155), ('D-summed_oscs', 0.09892847939228369), ('D-area_spectra', -0.0009989516975318013), ('D-area_sim_solar_spectra', 0.06413975398820689), ('D-chemical_potential', 0.0), ('D-electrophilicity', 0.033204447617025616), ('D-pi_sys_size', -0.015361925105358411), ('D-num_rot_bonds', 0.13120881426137768), ('D-MolLogP', 0.1051905175278103), ('D-TPSA', -0.015976209265112576), ('D-NumHAcceptors', 0.1961817579428205), ('D-NumHDonors', 0.0), ('D-RingCount', 0.007465073223772762), ('D-planarity', -0.23160491797007107), ('D-dipole_moment', -0.0732698596829198), ('D-polarizability', -0.004536105532554003), ('D-SolvationEnergy_water', 0.0), ('D-SolvationEnergy_hexane', 0.0), ('AD-overlap', 0.0021375686919477338), ('AD-HOMOoffset', 0.0), ('AD-LUMOoffset', -0.05899770237859954), ('DHOMO_ALUMO_offset', 0.0)]\n",
      "The 5-fold cross-validated RMSE of this model is,  2.91  +/-  0.0061\n",
      "The 5-fold cross-validated MAE of the average  2.222  +/-  0.004\n",
      "The average r^2 value is  0.4141092641420053  +/-  0.002\n"
     ]
    }
   ],
   "source": [
    "Lasso_PCE = evaluate_model(all_descriptors, data['PCE'], data, cf=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07715e20-b58d-40b3-bb55-558adf621de4",
   "metadata": {},
   "source": [
    "When the coefficient is zero, it means there is no correlation between the descriptor and the PCE, so it can be discarded.  \n",
    "The following descriptors were zeroed out:\n",
    "1. HOMO (acc & don)\n",
    "2. HOMO-1 (acc)\n",
    "3. fundamental bandgap (acc & don)\n",
    "4. optical bandgap (acc & don)\n",
    "5. chemical potential (acc & don)\n",
    "6. NumHDonors (acc & don)\n",
    "7. Solvation energies for water and hexane (acc & don)\n",
    "8. deltaHOMO (don)\n",
    "9. deltaLUMO (don)\n",
    "10. HOMO offset between donor and acceptor\n",
    "11. Offset between donor HOMO and acceptor LUMO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01418764-b798-4491-8550-96c630db1dcd",
   "metadata": {},
   "source": [
    "The remaining descriptors are hand-tuned to lower the RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "821e2d85-d87e-4ff0-a35e-8a986326a278",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A-LUMO', 'A-LUMOplus1', 'A-deltaHOMO', 'A-deltaLUMO', 'A-max_abs', 'A-summed_oscs', 'A-area_spectra', 'A-area_sim_solar_spectra', 'A-electrophilicity', 'A-pi_sys_size', 'A-num_rot_bonds', 'A-MolLogP', 'A-TPSA', 'A-NumHAcceptors', 'A-planarity', 'A-dipole_moment', 'A-polarizability', 'D-HOMOminus1', 'D-LUMO', 'D-LUMOplus1', 'D-max_abs', 'D-summed_oscs', 'D-area_spectra', 'D-area_sim_solar_spectra', 'D-electrophilicity', 'D-pi_sys_size', 'D-num_rot_bonds', 'D-MolLogP', 'D-TPSA', 'D-NumHAcceptors', 'D-planarity', 'D-dipole_moment', 'D-polarizability', 'AD-overlap', 'AD-LUMOoffset']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bripe\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6.781293106398152, tolerance: 1.4507535502977023\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\bripe\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 31.384951783514225, tolerance: 1.4507535502977023\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\bripe\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8.786145665426375, tolerance: 1.4507535502977023\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\bripe\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2.2772241456805205, tolerance: 1.4507535502977023\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\bripe\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.260510541649637, tolerance: 1.4507535502977023\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\bripe\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2.282502544549061, tolerance: 1.4507535502977023\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\bripe\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 70.73498220931742, tolerance: 1.4507535502977023\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\bripe\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 24.674763146816076, tolerance: 1.4507535502977023\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\bripe\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 23.753236227011257, tolerance: 1.4507535502977023\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\bripe\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5.990294182571233, tolerance: 1.4507535502977023\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\bripe\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.13262742337065, tolerance: 1.4507535502977023\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34\n",
      "2.9135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bripe\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6.383602071324276, tolerance: 1.4507535502977023\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\bripe\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 30.775178613127537, tolerance: 1.4507535502977023\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\bripe\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8.57423568455124, tolerance: 1.4507535502977023\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\bripe\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2.2667150969664362, tolerance: 1.4507535502977023\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\bripe\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.02869174305124, tolerance: 1.4507535502977023\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\bripe\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2.239054768853748, tolerance: 1.4507535502977023\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\bripe\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 72.48473122874748, tolerance: 1.4507535502977023\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\bripe\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 24.562403660802374, tolerance: 1.4507535502977023\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\bripe\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 23.67700429018896, tolerance: 1.4507535502977023\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\bripe\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5.834006099430553, tolerance: 1.4507535502977023\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\bripe\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.0625718640767445, tolerance: 1.4507535502977023\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n",
      "2.9108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bripe\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 24.301351982651795, tolerance: 1.4507535502977023\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\bripe\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6.025165096245473, tolerance: 1.4507535502977023\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\bripe\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.7502440586868033, tolerance: 1.4507535502977023\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\bripe\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5.288329381630319, tolerance: 1.4507535502977023\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\bripe\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2.7654079249496135, tolerance: 1.4507535502977023\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\bripe\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.8021353130952775, tolerance: 1.4507535502977023\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\bripe\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2.4987743007950485, tolerance: 1.4507535502977023\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\bripe\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.58912390049318, tolerance: 1.4507535502977023\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\bripe\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 10.754715273023976, tolerance: 1.4507535502977023\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\bripe\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.4640453134106792, tolerance: 1.4507535502977023\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\bripe\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 23.896206012603216, tolerance: 1.4507535502977023\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\bripe\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.0530502701803925, tolerance: 1.4507535502977023\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\bripe\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.4364885807754, tolerance: 1.4507535502977023\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\bripe\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.5672356891773234, tolerance: 1.4507535502977023\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n",
      "2.9095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bripe\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 24.306155209224016, tolerance: 1.4507535502977023\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\bripe\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6.057061871975748, tolerance: 1.4507535502977023\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\bripe\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.7463449306924304, tolerance: 1.4507535502977023\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\bripe\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5.324489222378361, tolerance: 1.4507535502977023\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\bripe\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2.7893016733887634, tolerance: 1.4507535502977023\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\bripe\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.8337253094941843, tolerance: 1.4507535502977023\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\bripe\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2.3274596461978945, tolerance: 1.4507535502977023\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\bripe\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.95695209141559, tolerance: 1.4507535502977023\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\bripe\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 10.496191342392194, tolerance: 1.4507535502977023\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\bripe\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.433170798494757, tolerance: 1.4507535502977023\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\bripe\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 23.880480846841238, tolerance: 1.4507535502977023\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\bripe\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.384104757751629, tolerance: 1.4507535502977023\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\bripe\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.52907656645766, tolerance: 1.4507535502977023\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\bripe\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.5518216047585156, tolerance: 1.4507535502977023\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31\n",
      "2.9085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bripe\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 24.001718903598885, tolerance: 1.4507535502977023\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\bripe\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5.9781181618564005, tolerance: 1.4507535502977023\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\bripe\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.7062921895540057, tolerance: 1.4507535502977023\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\bripe\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5.304513937702723, tolerance: 1.4507535502977023\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\bripe\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2.7624674436028727, tolerance: 1.4507535502977023\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\bripe\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.816240828635273, tolerance: 1.4507535502977023\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\bripe\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2.553716903739769, tolerance: 1.4507535502977023\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\bripe\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.00393140355936, tolerance: 1.4507535502977023\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\bripe\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 10.541430529434365, tolerance: 1.4507535502977023\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\bripe\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.4181886972273787, tolerance: 1.4507535502977023\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\bripe\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 24.96782234258808, tolerance: 1.4507535502977023\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\bripe\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5.132559676310848, tolerance: 1.4507535502977023\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\bripe\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6.3065746684369515, tolerance: 1.4507535502977023\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\bripe\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.4936008759777906, tolerance: 1.4507535502977023\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "2.9082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bripe\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 24.071758336947823, tolerance: 1.4507535502977023\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\bripe\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6.020821837357289, tolerance: 1.4507535502977023\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\bripe\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.7129853078440647, tolerance: 1.4507535502977023\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\bripe\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5.310130032267807, tolerance: 1.4507535502977023\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\bripe\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2.763661356684679, tolerance: 1.4507535502977023\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\bripe\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.8151695219785324, tolerance: 1.4507535502977023\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\bripe\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2.563876367696139, tolerance: 1.4507535502977023\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\bripe\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.05991859968526, tolerance: 1.4507535502977023\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\bripe\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 10.576109737254228, tolerance: 1.4507535502977023\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\bripe\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.4212568278908293, tolerance: 1.4507535502977023\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\bripe\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 24.929959260463875, tolerance: 1.4507535502977023\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\bripe\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5.1319778331089765, tolerance: 1.4507535502977023\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\bripe\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6.314683047163271, tolerance: 1.4507535502977023\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\bripe\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.4925233426565683, tolerance: 1.4507535502977023\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n",
      "2.9081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bripe\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5.42211745480563, tolerance: 1.4507535502977023\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\bripe\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.1097545924567385, tolerance: 1.4507535502977023\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\bripe\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2.308612215823814, tolerance: 1.4507535502977023\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\bripe\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.8263699089911825, tolerance: 1.4507535502977023\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\bripe\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.4724401852854498, tolerance: 1.4507535502977023\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\bripe\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 15.47469564525727, tolerance: 1.4507535502977023\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\bripe\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.025296182775492, tolerance: 1.4507535502977023\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\bripe\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2.579880038567353, tolerance: 1.4507535502977023\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\bripe\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2.9998961102719477, tolerance: 1.4507535502977023\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n",
      "2.908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bripe\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2.9619208471431193, tolerance: 1.4507535502977023\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\bripe\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2.8328546311240643, tolerance: 1.4507535502977023\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\bripe\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.075441451432198, tolerance: 1.4507535502977023\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\bripe\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2.2749035971355624, tolerance: 1.4507535502977023\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\bripe\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.7682683980037837, tolerance: 1.4507535502977023\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\bripe\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6.520131463032158, tolerance: 1.4507535502977023\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\bripe\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.883655185401949, tolerance: 1.4507535502977023\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\bripe\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2.8247974749592686, tolerance: 1.4507535502977023\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\bripe\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.1485498036454374, tolerance: 1.4507535502977023\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n",
      "2.9079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bripe\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2.741228766439235, tolerance: 1.4507535502977023\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\bripe\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2.7996958278818056, tolerance: 1.4507535502977023\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\bripe\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.026895278819211, tolerance: 1.4507535502977023\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\bripe\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2.273544587456854, tolerance: 1.4507535502977023\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\bripe\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.7682382396014873, tolerance: 1.4507535502977023\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\bripe\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6.518215559439341, tolerance: 1.4507535502977023\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\bripe\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.8808430512108316, tolerance: 1.4507535502977023\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\bripe\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2.824307470649728, tolerance: 1.4507535502977023\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\bripe\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.1497864651337295, tolerance: 1.4507535502977023\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n",
      "2.9079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bripe\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2.741228766439235, tolerance: 1.4507535502977023\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\bripe\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2.7996958278818056, tolerance: 1.4507535502977023\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\bripe\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.026916922037344, tolerance: 1.4507535502977023\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\bripe\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2.273544587456854, tolerance: 1.4507535502977023\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\bripe\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.7682382396014873, tolerance: 1.4507535502977023\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\bripe\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6.518215559439341, tolerance: 1.4507535502977023\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\bripe\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.8808430512108316, tolerance: 1.4507535502977023\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\bripe\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2.824307470649728, tolerance: 1.4507535502977023\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\bripe\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.1497864651337295, tolerance: 1.4507535502977023\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n",
      "2.9079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bripe\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.252493299627531, tolerance: 1.4507535502977023\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\bripe\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.2570693885936635, tolerance: 1.4507535502977023\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\bripe\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2.369651469778546, tolerance: 1.4507535502977023\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\bripe\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.829479173231448, tolerance: 1.4507535502977023\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\bripe\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.4636259296657954, tolerance: 1.4507535502977023\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\bripe\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5.967768215698015, tolerance: 1.4507535502977023\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\bripe\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.929915897313549, tolerance: 1.4507535502977023\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\bripe\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.0358925940818153, tolerance: 1.4507535502977023\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\bripe\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.3570190052214457, tolerance: 1.4507535502977023\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n",
      "2.908\n",
      "23\n",
      "2.908\n",
      "22\n",
      "2.908\n",
      "21\n",
      "2.9081\n",
      "20\n",
      "2.9083\n",
      "19\n",
      "2.9085\n",
      "18\n",
      "2.9079\n",
      "17\n",
      "2.9119\n",
      "16\n",
      "2.9155\n",
      "15\n",
      "2.9187\n",
      "14\n",
      "2.9229\n",
      "13\n",
      "2.927\n",
      "12\n",
      "2.9388\n",
      "11\n",
      "2.9556\n",
      "10\n",
      "2.9842\n",
      "9\n",
      "3.0081\n",
      "8\n",
      "3.0222\n",
      "7\n",
      "3.0494\n",
      "6\n",
      "3.0993\n",
      "['A-electrophilicity', 'A-num_rot_bonds', 'A-MolLogP', 'A-TPSA', 'D-HOMOminus1', 'D-NumHAcceptors']\n",
      "3.0993\n",
      "The average intercept from 5 folds is  -51.57087072184057\n",
      "The average coefficients of the 5 folds is  [('A-HOMO', 0.0), ('A-HOMOminus1', 0.0), ('A-LUMO', -0.17545975271623135), ('A-LUMOplus1', -0.37452985792697435), ('A-fundbg', 0.0), ('A-deltaHOMO', -2.257287427054922), ('A-deltaLUMO', -0.0010517494440340231), ('A-opt_bg', 0.0), ('A-max_abs', 0.012185671244768142), ('A-summed_oscs', -0.11552792341660978), ('A-area_spectra', -0.0024600261908346815), ('A-area_sim_solar_spectra', 0.06207173287218095), ('A-chemical_potential', 0.0), ('A-electrophilicity', -0.03011792426999103), ('A-pi_sys_size', -0.03922436041426376), ('A-num_rot_bonds', -0.39931444393768434), ('A-MolLogP', 0.3033117383147984), ('A-TPSA', 0.019222160253011905), ('A-NumHAcceptors', 0.06030204224934772), ('A-NumHDonors', 0.0), ('A-planarity', -0.16661875585035552), ('A-dipole_moment', -0.02827826710704328), ('A-polarizability', -0.0011481163925569366), ('A-SolvationEnergy_water', 0.0), ('A-SolvationEnergy_hexane', 0.0), ('D-HOMO', 0.0), ('D-HOMOminus1', -2.609560498762281), ('D-LUMO', -0.09153978351798593), ('D-LUMOplus1', -2.4630012027165327), ('D-fundbg', 0.0), ('D-deltaHOMO', 0.0), ('D-deltaLUMO', 0.0), ('D-opt_bg', 0.0), ('D-max_abs', -0.005792822722166216), ('D-summed_oscs', 0.061046950921234355), ('D-area_spectra', -0.0009257572306575465), ('D-area_sim_solar_spectra', 0.07486112837362366), ('D-chemical_potential', 0.0), ('D-electrophilicity', 0.019743047637750682), ('D-pi_sys_size', 0.0028551618219520873), ('D-num_rot_bonds', 0.1379674641410618), ('D-MolLogP', 0.09091670347420719), ('D-TPSA', -0.01842713958710088), ('D-NumHAcceptors', 0.19570504708200062), ('D-NumHDonors', 0.0), ('D-planarity', -0.197607592555249), ('D-dipole_moment', -0.05797453846768639), ('D-polarizability', -0.005094977289589237), ('D-SolvationEnergy_water', 0.0), ('D-SolvationEnergy_hexane', 0.0), ('AD-overlap', 0.0012525194003496043), ('AD-HOMOoffset', 0.0), ('AD-LUMOoffset', -0.004279434045421667), ('DHOMO_ALUMO_offset', 0.0)]\n",
      "The 5-fold cross-validated RMSE of this model is,  2.9167  +/-  0.00412\n",
      "The 5-fold cross-validated MAE of the average  2.23  +/-  0.003\n",
      "The average r^2 value is  0.41299670588474546  +/-  0.002\n"
     ]
    }
   ],
   "source": [
    "#best_descriptors = optimize_eq(data, 'PCE')\n",
    "Lasso_PCE = evaluate_model(best_descriptors, data['PCE'], data, cf=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "4aa4e951-53d2-420d-9b05-f5586f4997d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha is 0.01\n",
      "The average intercept from 5 folds is  -36.82762357618022\n",
      "The average coefficients of the 5 folds is  [('A-electrophilicity', -0.03673272675818182), ('A-num_rot_bonds', -0.3919236925943181), ('A-MolLogP', 0.12724213816888424), ('A-TPSA', 0.010438720700639826), ('D-HOMOminus1', -3.849560022147473), ('D-NumHAcceptors', 0.2502317935054116)]\n",
      "The 5-fold cross-validated RMSE of this model is,  3.0993  +/-  0.00088\n",
      "The 5-fold cross-validated MAE of the average  2.389  +/-  0.005\n",
      "The average r^2 value is  0.3372375057734442  +/-  0.0\n"
     ]
    }
   ],
   "source": [
    "best_descriptors = ['A-electrophilicity', 'A-num_rot_bonds', 'A-MolLogP', 'A-TPSA', 'D-HOMOminus1', 'D-NumHAcceptors']\n",
    "Lasso_PCE = evaluate_model(best_descriptors, data['PCE'], data, cf=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec6dd6c-f2e4-4cdd-b01c-5e28e4e7b108",
   "metadata": {},
   "source": [
    "Using LASSO and some hand-tuning to narrow it down to 6 descriptors, the RMSE of this model is 3.0993 +/- 0.00088 for the PCE. The $R^2$ is 0.337. The descriptors selected is the electrophilicity index of the acceptor, number of rotatable bonds of the acceptor, MolLogP of the acceptor, TPSA of the acceptor, HOMO-1 of the donor, and number of hydrogen acceptors of the donor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e529f5d4-25c7-40e3-a7f7-ad44ff196484",
   "metadata": {},
   "source": [
    "### Performance on PCE > 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ae8a9a46-9fe8-4308-bc2b-26a2825cbb7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha is 0.01\n",
      "The average intercept from 5 folds is  -11.513850156052039\n",
      "The average coefficients of the 5 folds is  [('A-HOMO', 0.0), ('A-HOMOminus1', 0.0), ('A-LUMO', 0.0), ('A-LUMOplus1', -0.7049534956656617), ('A-fundbg', 0.0), ('A-deltaHOMO', -2.121462851530139), ('A-deltaLUMO', 0.0), ('A-opt_bg', 0.0), ('A-max_abs', 0.011421667421522202), ('A-summed_oscs', -0.2247221104885379), ('A-area_spectra', -0.0015466615727089867), ('A-area_sim_solar_spectra', 0.464514918259573), ('A-chemical_potential', 0.0), ('A-electrophilicity', -0.006314366764445796), ('A-pi_sys_size', -0.040522031107699495), ('A-num_rot_bonds', -0.11609582244389387), ('A-MolLogP', 0.13513432383667234), ('A-TPSA', 0.0013573775176714768), ('A-NumHAcceptors', 0.10115431934774391), ('A-NumHDonors', -0.1771381772989141), ('A-RingCount', 0.14754188685927655), ('A-planarity', -0.18058750830251555), ('A-dipole_moment', -0.03541930306629818), ('A-polarizability', -0.004390787538192751), ('A-SolvationEnergy_water', 0.0), ('A-SolvationEnergy_hexane', 0.0), ('D-HOMO', 0.0), ('D-HOMOminus1', 0.0), ('D-LUMO', 0.0), ('D-LUMOplus1', 0.1512709591704097), ('D-fundbg', 0.0), ('D-deltaHOMO', 0.0), ('D-deltaLUMO', 0.20616843476189714), ('D-opt_bg', 0.0), ('D-max_abs', 0.0033376690454637245), ('D-summed_oscs', 0.08933934430296435), ('D-area_spectra', -0.0011602762976147304), ('D-area_sim_solar_spectra', 0.05212918154741528), ('D-chemical_potential', 0.0), ('D-electrophilicity', 0.05570742574314628), ('D-pi_sys_size', -0.023657336374784406), ('D-num_rot_bonds', 0.0004833972107449777), ('D-MolLogP', -0.02462449586412331), ('D-TPSA', -0.014648557081410135), ('D-NumHAcceptors', 0.1473138060081931), ('D-NumHDonors', 0.0), ('D-RingCount', -0.009159099808956161), ('D-planarity', -0.27083773085431506), ('D-dipole_moment', -0.011121286966211287), ('D-polarizability', 0.0016603329852793631), ('D-SolvationEnergy_water', 0.0), ('D-SolvationEnergy_hexane', 0.0), ('AD-overlap', 0.0019561747435623933), ('AD-HOMOoffset', 0.0), ('AD-LUMOoffset', 0.0), ('DHOMO_ALUMO_offset', 0.0)]\n",
      "The 5-fold cross-validated RMSE of this model is,  1.4072  +/-  0.00528\n",
      "The 5-fold cross-validated MAE of the average  1.097  +/-  0.004\n",
      "The average r^2 value is  0.46512713595505956  +/-  0.004\n"
     ]
    }
   ],
   "source": [
    "Lasso_highPCE = evaluate_model(all_descriptors, data_highPCE['PCE'], data_highPCE, cf=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "86615ffb-2d82-4a8b-9a6a-83658e0d97fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha is 0.01\n",
      "The average intercept from 5 folds is  -4.267204924215006\n",
      "The average coefficients of the 5 folds is  [('A-deltaHOMO', -2.083737185992404), ('A-max_abs', 0.013736351224865473), ('A-num_rot_bonds', -0.18542951442278338), ('D-area_spectra', -0.0006769547389177241), ('D-electrophilicity', 0.04156378924271681), ('D-TPSA', -0.01456558372358307), ('D-NumHAcceptors', 0.09444544003183006), ('AD-overlap', 0.0022508957326855894)]\n",
      "The 5-fold cross-validated RMSE of this model is,  1.4833  +/-  0.00072\n",
      "The 5-fold cross-validated MAE of the average  1.187  +/-  0.001\n",
      "The average r^2 value is  0.4057400141644918  +/-  0.001\n"
     ]
    }
   ],
   "source": [
    "#best_descriptors = optimize_eq(data_highPCE, 'PCE')\n",
    "best_descriptors = ['A-deltaHOMO', 'A-max_abs', 'A-num_rot_bonds', 'D-area_spectra', 'D-electrophilicity', 'D-TPSA', 'D-NumHAcceptors', 'AD-overlap']\n",
    "Lasso_PCE = evaluate_model(best_descriptors, data_highPCE['PCE'], data_highPCE, cf=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32beb4c3-16c9-4c27-94fe-96edf74d0cae",
   "metadata": {},
   "source": [
    "# Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d48fd1d-789c-4cb3-9863-a0efb888d179",
   "metadata": {},
   "source": [
    "Sets X as all input descriptors and y as the PCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc64fd96-4fd3-4c5c-9b29-2b3ef11c060e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:, 8:]\n",
    "y = data.iloc[:, 7:8]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "577025d1-11bb-402f-9209-314b7284d4db",
   "metadata": {},
   "source": [
    "Split into training (80%) and testing (20%) sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc9eafe7-2652-4db3-b57a-25d9d05c4fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90c4657-ae34-4fbe-b3aa-c9a41a7421d7",
   "metadata": {},
   "source": [
    "Standardizes the data so all values are centered around 0 and have variance of the same magnitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6fcd702-82e7-4874-b04b-a1dac3ea381b",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''x_labels = x_train.columns\n",
    "\n",
    "scaler = StandardScaler().fit(x_train[x_labels]) \n",
    "\n",
    "x_train[x_labels] = scaler.transform(x_train[x_labels])\n",
    "\n",
    "x_test[x_labels] = scaler.transform(x_test[x_labels])'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64973c2-0c95-4bbf-bca3-e0b09bead5d9",
   "metadata": {},
   "source": [
    "Optimize alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ad74352-613c-4b3c-9c62-b4b381de6ec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha is 0.7704750571710461\n",
      "[(-0.0, 'A-HOMO'), (0.0, 'A-HOMOminus1'), (-0.0, 'A-LUMO'), (-0.0, 'A-LUMOplus1'), (-0.0, 'A-fundbg'), (-0.0, 'A-deltaHOMO'), (-0.0, 'A-deltaLUMO'), (-0.0, 'A-opt_bg'), (0.017641186867352908, 'A-max_abs'), (0.0, 'A-summed_oscs'), (-0.0001404467196195648, 'A-area_spectra'), (0.0, 'A-area_sim_solar_spectra'), (-0.0, 'A-chemical_potential'), (-0.019170290099192057, 'A-electrophilicity'), (-0.02482452620409847, 'A-pi_sys_size'), (-0.239271484909954, 'A-num_rot_bonds'), (0.021551740089278786, 'A-MolLogP'), (0.013085813850718133, 'A-TPSA'), (0.0, 'A-NumHAcceptors'), (-0.0, 'A-NumHDonors'), (-0.0, 'A-planarity'), (-0.011609710654258832, 'A-dipole_moment'), (0.0016297906802177796, 'A-polarizability'), (-0.0, 'A-SolvationEnergy_water'), (0.0, 'A-SolvationEnergy_hexane'), (-0.0, 'D-HOMO'), (-0.0, 'D-HOMOminus1'), (-0.0, 'D-LUMO'), (-0.0, 'D-LUMOplus1'), (-0.0, 'D-fundbg'), (-0.0, 'D-deltaHOMO'), (-0.0, 'D-deltaLUMO'), (-0.0, 'D-opt_bg'), (0.001697891868806389, 'D-max_abs'), (0.0, 'D-summed_oscs'), (-0.00027146013347161907, 'D-area_spectra'), (-0.0, 'D-area_sim_solar_spectra'), (-0.0, 'D-chemical_potential'), (0.04668917769591438, 'D-electrophilicity'), (0.0, 'D-pi_sys_size'), (0.0, 'D-num_rot_bonds'), (0.0, 'D-MolLogP'), (0.0015197702671379846, 'D-TPSA'), (0.07693889646606056, 'D-NumHAcceptors'), (0.0, 'D-NumHDonors'), (-0.0, 'D-planarity'), (0.0, 'D-dipole_moment'), (0.002427305200541985, 'D-polarizability'), (-0.0, 'D-SolvationEnergy_water'), (-0.0, 'D-SolvationEnergy_hexane'), (0.0008862458388471071, 'AD-overlap'), (-0.0, 'AD-HOMOoffset'), (-0.0, 'AD-LUMOoffset'), (0.0, 'DHOMO_ALUMO_offset')]\n",
      "R squared training set 0.36\n",
      "R squared test set 0.25\n"
     ]
    }
   ],
   "source": [
    "lasso = LassoCV(cv=5, random_state=14, max_iter=10000)\n",
    "lasso.fit(x_train, y_train)\n",
    "print('Best alpha is ' + str(lasso.alpha_))\n",
    "\n",
    "print(list(zip(lasso.coef_, X)))\n",
    "print('R squared training set', round(lasso.score(x_train, y_train), 2))\n",
    "print('R squared test set', round(lasso.score(x_test, y_test), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb2df60-8d3d-4977-926d-485562962f84",
   "metadata": {},
   "source": [
    "Visualize the optimization of alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "8b14e4e8-e6ed-4f70-87c6-b7c36cca970c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "alphas = np.linspace(0.001,1,1000)\n",
    "lasso = Lasso(max_iter=10000)\n",
    "\n",
    "scores = []\n",
    "for a in alphas:\n",
    "    lasso.set_params(alpha=a)\n",
    "    lasso.fit(x_train, y_train)\n",
    "    \n",
    "    #scores.append(lasso.score(x_train, y_train))\n",
    "    scores.append(cross_val_score(lasso, x_train, y_train, cv=5).mean())\n",
    "\n",
    "plt.figure(figsize=(5, 3))  \n",
    "plt.plot(alphas, scores)\n",
    "plt.xlim([0, 1])\n",
    "plt.xlabel('alpha')\n",
    "plt.ylabel('$R^2$')\n",
    "plt.tight_layout()\n",
    "plt.savefig('lasso_cv_alpha.pdf', dpi=600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13c0e0c-7dd6-402b-9de2-22b726fc19a2",
   "metadata": {},
   "source": [
    "Final model metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eaca3d3e-cd84-4440-959d-dcb661b9d5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_metrics(model, X, y, cv=5):\n",
    "    score = cross_val_score(model, X, y, cv=cv, scoring = 'r2')\n",
    "    SEM_r2 = round((score.std() / math.sqrt(5)) , 3)\n",
    "    #r2 = str(round(score.mean(), 3)) + ' +/- ' +  str(SEM_r2)\n",
    "    r2 = round(float(score.mean()), 3)\n",
    "    print('R^2: ' + str(r2) + ' +/- ' +  str(SEM_r2))\n",
    "    \n",
    "    score = cross_val_score(model, X, y, cv=cv, scoring = 'neg_mean_absolute_error')\n",
    "    score = np.multiply(score, -1)\n",
    "    SEM_MAE = round((score.std() / math.sqrt(5)) , 2)\n",
    "    #MAE = str(round(score.mean(), 2)) + ' +/- ' +  str(SEM_MAE)\n",
    "    MAE = round(score.mean(), 2) \n",
    "    print('MAE: ' + str(MAE) + ' +/- ' +  str(SEM_MAE))\n",
    "    \n",
    "    score = cross_val_score(model, X, y, cv=cv, scoring = 'neg_mean_squared_error')\n",
    "    score = np.sqrt(score * -1)\n",
    "    SEM_RMSE = round((score.std() / math.sqrt(5)) , 2)\n",
    "    #RMSE = str(round(score.mean(), 2)) + ' +/- ' +  str(SEM_RMSE)\n",
    "    RMSE = round(score.mean(), 2)\n",
    "    print('RMSE: ' + str(RMSE) + ' +/- ' +  str(SEM_RMSE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "02354f17-b7d8-44bf-ae78-46197057d235",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set\n",
      "R^2: 0.312 +/- 0.042\n",
      "MAE: 2.47 +/- 0.07\n",
      "RMSE: 3.19 +/- 0.09\n",
      "Test set\n",
      "R^2: 0.135 +/- 0.018\n",
      "MAE: 2.52 +/- 0.07\n",
      "RMSE: 3.29 +/- 0.08\n"
     ]
    }
   ],
   "source": [
    "print('Training set')\n",
    "model_metrics(lasso, x_train, y_train, cv=5)\n",
    "\n",
    "print('Test set')\n",
    "model_metrics(lasso, x_test, y_test, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5a434a-27fd-4fde-b709-13ca711f6145",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13716c29-2d08-4b18-8a50-63cfee32cba0",
   "metadata": {},
   "source": [
    "Find best hyperparameters with randomized search, then use those narrowed down parameters for a gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "91bda905-7274-4afb-aa87-deadf118540d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 916,\n",
       " 'min_samples_split': 10,\n",
       " 'min_samples_leaf': 2,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_depth': 26,\n",
       " 'bootstrap': False}"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestRegressor(random_state=14)\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 50, stop = 2000, num = 10)]\n",
    "\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(3, 50, num = 5)]\n",
    "max_depth.append(None)\n",
    "\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rf = RandomForestRegressor()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "rf_random.fit(x_train, y_train)\n",
    "\n",
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "5e33f470-d6d7-4b91-b641-cb1c9311ef3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 162 candidates, totalling 486 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'bootstrap': False,\n",
       " 'max_depth': 30,\n",
       " 'max_features': 17,\n",
       " 'min_samples_leaf': 2,\n",
       " 'min_samples_split': 12,\n",
       " 'n_estimators': 100}"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the parameter grid based on the results of random search \n",
    "param_grid = {\n",
    "    'bootstrap': [False],\n",
    "    'max_depth': [10, 25, 30],\n",
    "    'max_features': [17, 30],\n",
    "    'min_samples_leaf': [2, 3, 4],\n",
    "    'min_samples_split': [8, 10, 12],\n",
    "    'n_estimators': [100, 500, 1000]\n",
    "}\n",
    "# Create a based model\n",
    "rf = RandomForestRegressor()\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, \n",
    "                          cv = 3, n_jobs = -1, verbose = 2)\n",
    "grid_search.fit(x_train, y_train)\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "e0d08ca3-017b-4430-84eb-b231bc1bdf5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set\n",
      "R^2: 0.486 +/- 0.037\n",
      "MAE: 2.07 +/- 0.08\n",
      "RMSE: 2.75 +/- 0.09\n",
      "test set\n",
      "R^2: 0.22 +/- 0.013\n",
      "MAE: 2.37 +/- 0.09\n",
      "RMSE: 3.13 +/- 0.1\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestRegressor(n_estimators=100,max_depth=30, min_samples_split=2, min_samples_leaf=2, max_features=17, random_state=14)\n",
    "rf.fit(x_train, y_train)\n",
    "print('training set')\n",
    "model_metrics(rf, x_train, y_train, cv=5)\n",
    "print('test set')\n",
    "model_metrics(rf, x_test, y_test, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7604c3cf-b2d6-413d-ad13-e766fd4cde10",
   "metadata": {},
   "source": [
    "These results are slightly better than LASSO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72614e5b-8cad-435d-bc6c-2a1afc9ddbea",
   "metadata": {},
   "source": [
    "## Gradient boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "8ea3f976-66f5-4dd4-9ff1-e530708a55f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 256 candidates, totalling 768 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.02, 'max_depth': 6, 'n_estimators': 1000, 'subsample': 0.5}"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# Create the parameter grid\n",
    "param_grid = {'learning_rate': [0.01,0.02,0.03,0.04],\n",
    "                  'subsample'    : [0.9, 0.5, 0.2, 0.1],\n",
    "                  'n_estimators' : [100,500,1000, 1500],\n",
    "                  'max_depth'    : [4,6,8,10]\n",
    "                 }\n",
    "# Create a based model\n",
    "gb = GradientBoostingRegressor()\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = gb, param_grid = param_grid, \n",
    "                          cv = 3, n_jobs = -1, verbose = 2)\n",
    "grid_search.fit(x_train, y_train)\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "4f3151f0-04b0-4edc-b57f-c2081e30e810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set\n",
      "R^2: 0.482 +/- 0.036\n",
      "MAE: 2.05 +/- 0.09\n",
      "RMSE: 2.76 +/- 0.09\n",
      "test set\n",
      "R^2: 0.143 +/- 0.035\n",
      "MAE: 2.5 +/- 0.13\n",
      "RMSE: 3.28 +/- 0.15\n"
     ]
    }
   ],
   "source": [
    "gb = GradientBoostingRegressor(learning_rate = 0.02, subsample = 0.5, n_estimators = 1000, max_depth=6, random_state=14)\n",
    "\n",
    "gb.fit(x_train, y_train.values.ravel())\n",
    "print('training set')\n",
    "model_metrics(gb, x_train, y_train, cv=5)\n",
    "print('test set')\n",
    "model_metrics(gb, x_test, y_test, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde935b2-7850-4e24-b23c-1035bcc54516",
   "metadata": {},
   "source": [
    "Random forest is still performing the best"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c362177-75b9-453e-938c-302f1cfe4a18",
   "metadata": {},
   "source": [
    "## XGBoost for random forest (XGBRFR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "efadb102-7813-412d-89ec-c6c7753c9fb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set\n",
      "R^2: 0.444 +/- 0.039\n",
      "MAE: 2.2 +/- 0.08\n",
      "RMSE: 2.86 +/- 0.09\n",
      "test set\n",
      "R^2: 0.214 +/- 0.018\n",
      "MAE: 2.39 +/- 0.11\n",
      "RMSE: 3.14 +/- 0.11\n"
     ]
    }
   ],
   "source": [
    "xgbrfr = XGBRFRegressor(n_estimators=1000, subsample=0.9, colsample_bynode=0.1, random_state=14)\n",
    "xgbrfr.fit(x_train, y_train.values.ravel())\n",
    "print('training set')\n",
    "model_metrics(xgbrfr, x_train, y_train, cv=5)\n",
    "print('test set')\n",
    "model_metrics(xgbrfr, x_test, y_test, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72906535-6405-4ae4-9f01-2553490f4a08",
   "metadata": {},
   "source": [
    "## Support Vector Regression (SVR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "fd766d34-fdfe-46e4-8c71-5285b49a2f9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set\n",
      "R^2: 0.398 +/- 0.041\n",
      "MAE: 2.29 +/- 0.08\n",
      "RMSE: 2.98 +/- 0.09\n",
      "test set\n",
      "R^2: 0.162 +/- 0.025\n",
      "MAE: 2.47 +/- 0.13\n",
      "RMSE: 3.25 +/- 0.13\n"
     ]
    }
   ],
   "source": [
    "svr_rbf = SVR(kernel=\"rbf\", C=1, gamma='auto', epsilon=0.1)\n",
    "svr_rbf.fit(x_train, y_train.values.ravel())\n",
    "print('training set')\n",
    "model_metrics(svr_rbf, x_train, y_train, cv=5)\n",
    "print('test set')\n",
    "model_metrics(svr_rbf, x_test, y_test, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c0e485-7d79-4784-bf26-0bf31d677474",
   "metadata": {},
   "source": [
    "## K-nearest neighboors (KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "7f1bdc9e-ea3b-4558-b0ab-86e330915090",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set\n",
      "R^2: 0.391 +/- 0.026\n",
      "MAE: 2.25 +/- 0.06\n",
      "RMSE: 3.0 +/- 0.06\n",
      "test set\n",
      "R^2: 0.222 +/- 0.027\n",
      "MAE: 2.33 +/- 0.1\n",
      "RMSE: 3.12 +/- 0.11\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsRegressor(n_neighbors=4)\n",
    "knn.fit(x_train, y_train.values.ravel())\n",
    "print('training set')\n",
    "model_metrics(knn, x_train, y_train, cv=5)\n",
    "print('test set')\n",
    "model_metrics(knn, x_test, y_test, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e11bec9-7c6e-4bd8-abae-9928618320bb",
   "metadata": {},
   "source": [
    "## LightGBM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9a3ecb43-9208-40ed-b16c-a6f41ec75f0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set\n",
      "R^2: 0.371 +/- 0.03\n",
      "MAE: 2.4 +/- 0.07\n",
      "RMSE: 3.05 +/- 0.07\n",
      "test set\n",
      "R^2: 0.137 +/- 0.013\n",
      "MAE: 2.53 +/- 0.1\n",
      "RMSE: 3.29 +/- 0.1\n"
     ]
    }
   ],
   "source": [
    "lgbm = LGBMRegressor(n_estimators=10, max_depth=5, num_leaves=2**5, learning_rate=0.1)\n",
    "lgbm.fit(x_train, y_train.values.ravel())\n",
    "print('training set')\n",
    "model_metrics(lgbm, x_train, y_train, cv=5)\n",
    "print('test set')\n",
    "model_metrics(lgbm, x_test, y_test, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2d946b-8942-400c-afa1-0c9a8304c642",
   "metadata": {},
   "source": [
    "# Performance of models with morgan fingerprints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de79973-efc0-4d1a-a33c-04bd7a093e5c",
   "metadata": {},
   "source": [
    "We can add in morgan fingerprints and see if the performance improves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "cecfa768-d57d-4545-8a87-11bd1b77a40c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of donor-acceptor pairs is: 999\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('descriptors_with_fingerprints.csv')\n",
    "print('Number of donor-acceptor pairs is: ' + str(len(data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d8eef2-97de-4403-8b48-77dd59846426",
   "metadata": {},
   "source": [
    "Standardizes the descrptors (not including fingerprints) and then concats the fingerprints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "9cbfecf2-4d1a-4e7a-bc2a-49a617ae3410",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#standardize\\nx_labels = X_unstandardized.columns\\nscaler = StandardScaler().fit(X_unstandardized[x_labels]) \\nX_unstandardized[x_labels] = scaler.transform(X_unstandardized[x_labels])\\n\\nfps = data.iloc[:,64:]\\nX = pd.concat([X_unstandardized, fps], axis=1)'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data.iloc[:, 8:]\n",
    "y = data.iloc[:, 7:8]\n",
    "'''\n",
    "#standardize\n",
    "x_labels = X_unstandardized.columns\n",
    "scaler = StandardScaler().fit(X_unstandardized[x_labels]) \n",
    "X_unstandardized[x_labels] = scaler.transform(X_unstandardized[x_labels])\n",
    "\n",
    "fps = data.iloc[:,64:]\n",
    "X = pd.concat([X_unstandardized, fps], axis=1)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "23019a6b-6c00-4dee-a9a6-f71d65fc6c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into training and testing\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ca8378-3ac6-4762-a046-4366b3fdb572",
   "metadata": {},
   "source": [
    "## Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dab5fe76-3df3-47a8-9fb2-8411dc34abfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set\n",
      "R^2: 0.37 +/- 0.032\n",
      "MAE: 2.27 +/- 0.06\n",
      "RMSE: 3.01 +/- 0.09\n",
      "test set\n",
      "R^2: 0.09 +/- 0.072\n",
      "MAE: 2.84 +/- 0.07\n",
      "RMSE: 3.54 +/- 0.17\n"
     ]
    }
   ],
   "source": [
    "lasso = Lasso(alpha=0.01, random_state=14, max_iter=10000)\n",
    "lasso.fit(x_train, y_train)\n",
    "#print('Best alpha is ' + str(lasso.alpha_))\n",
    "\n",
    "print('training set')\n",
    "model_metrics(lasso, x_train, y_train, cv=5)\n",
    "print('test set')\n",
    "model_metrics(lasso, x_test, y_test, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b3d663-dc0d-4d4f-b5f9-1138313be914",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1fdc10b8-3098-45ae-936d-fcfd72b919a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set\n",
      "R^2: 0.499 +/- 0.04\n",
      "MAE: 1.99 +/- 0.07\n",
      "RMSE: 2.68 +/- 0.13\n",
      "test set\n",
      "R^2: 0.296 +/- 0.033\n",
      "MAE: 2.48 +/- 0.09\n",
      "RMSE: 3.14 +/- 0.19\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestRegressor(n_estimators=100,max_depth=30, min_samples_split=2, min_samples_leaf=2, max_features=17, random_state=14)\n",
    "rf.fit(x_train, y_train)\n",
    "print('training set')\n",
    "model_metrics(rf, x_train, y_train, cv=5)\n",
    "print('test set')\n",
    "model_metrics(rf, x_test, y_test, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01497267-cfd3-402f-9b4f-017e600fc38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = [10, 100, 500, 1000] \n",
    "max_depth = [10, 30, 50, 100]\n",
    "min_samples_split = [2, 5, 7]\n",
    "min_samples_leaf = [2, 4, 6]\n",
    "# max features had the biggest impact\n",
    "max_features = [30, 40, 50, 60, 70]\n",
    "for x in max_features:\n",
    "    print(x)\n",
    "    rf = RandomForestRegressor(n_estimators=1000,max_depth=30, min_samples_split=2, min_samples_leaf=2, max_features=50, random_state=14)\n",
    "    rf.fit(x_train, y_train)\n",
    "    print('test set')\n",
    "    model_metrics(rf, x_test, y_test, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c379bbcc-877f-4efd-bf5f-7b8a6d8ca192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set\n",
      "R^2: 0.502 +/- 0.042\n",
      "MAE: 1.98 +/- 0.07\n",
      "RMSE: 2.67 +/- 0.13\n",
      "test set\n",
      "R^2: 0.275 +/- 0.05\n",
      "MAE: 2.54 +/- 0.13\n",
      "RMSE: 3.19 +/- 0.23\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestRegressor(n_estimators=1000,max_depth=30, min_samples_split=2, min_samples_leaf=2, max_features=50, random_state=14)\n",
    "rf.fit(x_train, y_train)\n",
    "print('training set')\n",
    "model_metrics(rf, x_train, y_train, cv=5)\n",
    "print('test set')\n",
    "model_metrics(rf, x_test, y_test, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "067769eb-da03-485a-9389-5fc16bf1b5b8",
   "metadata": {},
   "source": [
    "## Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "532a04b1-8cd9-45d3-abad-8b01141dcc2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set\n",
      "R^2: 0.531 +/- 0.04\n",
      "MAE: 1.93 +/- 0.08\n",
      "RMSE: 2.63 +/- 0.1\n",
      "test set\n",
      "R^2: 0.194 +/- 0.043\n",
      "MAE: 2.46 +/- 0.14\n",
      "RMSE: 3.18 +/- 0.15\n"
     ]
    }
   ],
   "source": [
    "gb = GradientBoostingRegressor(learning_rate = 0.02, subsample = 0.5, n_estimators = 1000, max_depth=6, random_state=14)\n",
    "\n",
    "gb.fit(x_train, y_train.values.ravel())\n",
    "print('training set')\n",
    "model_metrics(gb, x_train, y_train, cv=5)\n",
    "print('test set')\n",
    "model_metrics(gb, x_test, y_test, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "78b467c4-30ca-442f-be48-063b85afc1dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "test set\n",
      "R^2: 0.232 +/- 0.035\n",
      "MAE: 2.39 +/- 0.13\n",
      "RMSE: 3.11 +/- 0.13\n",
      "12\n",
      "test set\n",
      "R^2: 0.254 +/- 0.026\n",
      "MAE: 2.35 +/- 0.12\n",
      "RMSE: 3.06 +/- 0.12\n",
      "13\n",
      "test set\n",
      "R^2: 0.224 +/- 0.038\n",
      "MAE: 2.39 +/- 0.13\n",
      "RMSE: 3.12 +/- 0.14\n",
      "14\n",
      "test set\n",
      "R^2: 0.232 +/- 0.035\n",
      "MAE: 2.38 +/- 0.13\n",
      "RMSE: 3.11 +/- 0.13\n",
      "15\n",
      "test set\n",
      "R^2: 0.232 +/- 0.035\n",
      "MAE: 2.38 +/- 0.13\n",
      "RMSE: 3.11 +/- 0.13\n"
     ]
    }
   ],
   "source": [
    "n_estimators = [90, 100, 110]\n",
    "subsample = [0.3, 0.5]\n",
    "learning_rate = [0.015, 0.02, 0.025]\n",
    "max_depth = [11, 12, 13, 14, 15]\n",
    "\n",
    "for x in max_depth:\n",
    "    print(x)\n",
    "    gb = GradientBoostingRegressor(learning_rate = 0.015, subsample = 0.3, n_estimators = 100, max_depth=12, random_state=14)\n",
    "    gb.fit(x_train, y_train.values.ravel())\n",
    "    print('test set')\n",
    "    model_metrics(gb, x_test, y_test, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "56663436-abf4-4834-a4be-b1590dac4ad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set\n",
      "R^2: 0.468 +/- 0.04\n",
      "MAE: 2.12 +/- 0.07\n",
      "RMSE: 2.76 +/- 0.12\n",
      "test set\n",
      "R^2: 0.27 +/- 0.034\n",
      "MAE: 2.59 +/- 0.1\n",
      "RMSE: 3.19 +/- 0.19\n"
     ]
    }
   ],
   "source": [
    "gb = GradientBoostingRegressor(learning_rate = 0.015, subsample = 0.3, n_estimators = 100, max_depth=12, random_state=14)\n",
    "gb.fit(x_train, y_train.values.ravel())\n",
    "print('training set')\n",
    "model_metrics(gb, x_train, y_train, cv=5)\n",
    "print('test set')\n",
    "model_metrics(gb, x_test, y_test, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bdc60fc-fc05-4ad7-8437-9b610b8bae15",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "74dccb63-ff6e-4488-b3db-1f8804f872f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set\n",
      "R^2: 0.474 +/- 0.038\n",
      "MAE: 2.11 +/- 0.07\n",
      "RMSE: 2.79 +/- 0.09\n",
      "test set\n",
      "R^2: 0.255 +/- 0.02\n",
      "MAE: 2.33 +/- 0.1\n",
      "RMSE: 3.06 +/- 0.1\n"
     ]
    }
   ],
   "source": [
    "xgbrfr = XGBRFRegressor(n_estimators=1000, subsample=0.9, colsample_bynode=0.1, random_state=14)\n",
    "xgbrfr.fit(x_train, y_train.values.ravel())\n",
    "print('training set')\n",
    "model_metrics(xgbrfr, x_train, y_train, cv=5)\n",
    "print('test set')\n",
    "model_metrics(xgbrfr, x_test, y_test, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a6749a97-5236-4530-9a93-2980bbccb9ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03\n",
      "test set\n",
      "R^2: 0.283 +/- 0.018\n",
      "MAE: 2.29 +/- 0.11\n",
      "RMSE: 3.0 +/- 0.1\n",
      "0.02\n",
      "test set\n",
      "R^2: 0.277 +/- 0.02\n",
      "MAE: 2.29 +/- 0.1\n",
      "RMSE: 3.01 +/- 0.1\n",
      "0.04\n",
      "test set\n",
      "R^2: 0.283 +/- 0.019\n",
      "MAE: 2.29 +/- 0.1\n",
      "RMSE: 3.0 +/- 0.1\n"
     ]
    }
   ],
   "source": [
    "n_estimators = [10, 100, 500, 1000, 5000]\n",
    "subsample = [0.25, 0.3, 0.35]\n",
    "colsample_bynode = [0.03, 0.02, 0.04]\n",
    "\n",
    "for x in colsample_bynode:\n",
    "    print(x)\n",
    "    xgbrfr = XGBRFRegressor(n_estimators=500, subsample=0.35, colsample_bynode=0.03, random_state=14)\n",
    "    xgbrfr.fit(x_train, y_train.values.ravel())\n",
    "    print('test set')\n",
    "    model_metrics(xgbrfr, x_test, y_test, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "df4b954b-36ba-4a9b-8cb6-d4b7de3c1df0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set\n",
      "R^2: 0.4 +/- 0.032\n",
      "MAE: 2.27 +/- 0.05\n",
      "RMSE: 2.93 +/- 0.09\n",
      "test set\n",
      "R^2: 0.296 +/- 0.024\n",
      "MAE: 2.47 +/- 0.09\n",
      "RMSE: 3.14 +/- 0.17\n"
     ]
    }
   ],
   "source": [
    "xgbrfr = XGBRFRegressor(n_estimators=500, subsample=0.35, colsample_bynode=0.03, random_state=14)\n",
    "xgbrfr.fit(x_train, y_train.values.ravel())\n",
    "print('training set')\n",
    "model_metrics(xgbrfr, x_train, y_train, cv=5)\n",
    "print('test set')\n",
    "model_metrics(xgbrfr, x_test, y_test, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ad066b-27b7-4c3f-91e5-10a2b8d54508",
   "metadata": {},
   "source": [
    "## SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1902f271-e290-4a08-aa82-dd8705846452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set\n",
      "R^2: 0.279 +/- 0.031\n",
      "MAE: 2.53 +/- 0.05\n",
      "RMSE: 3.27 +/- 0.06\n",
      "test set\n",
      "R^2: 0.057 +/- 0.019\n",
      "MAE: 2.61 +/- 0.11\n",
      "RMSE: 3.44 +/- 0.1\n"
     ]
    }
   ],
   "source": [
    "svr_rbf = SVR(kernel=\"rbf\", C=1, gamma='auto', epsilon=0.1)\n",
    "svr_rbf.fit(x_train, y_train.values.ravel())\n",
    "print('training set')\n",
    "model_metrics(svr_rbf, x_train, y_train, cv=5)\n",
    "print('test set')\n",
    "model_metrics(svr_rbf, x_test, y_test, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "6cbd0956-0fa9-45cf-8fcb-75133dc74c39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.35\n",
      "test set\n",
      "R^2: 0.3 +/- 0.034\n",
      "MAE: 2.16 +/- 0.06\n",
      "RMSE: 2.96 +/- 0.09\n",
      "0.4\n",
      "test set\n",
      "R^2: 0.3 +/- 0.034\n",
      "MAE: 2.16 +/- 0.07\n",
      "RMSE: 2.96 +/- 0.09\n",
      "0.45\n",
      "test set\n",
      "R^2: 0.3 +/- 0.033\n",
      "MAE: 2.17 +/- 0.07\n",
      "RMSE: 2.96 +/- 0.09\n"
     ]
    }
   ],
   "source": [
    "C = [70, 60]\n",
    "epsilon = [0.35, 0.4, 0.45]\n",
    "for n in epsilon:\n",
    "    print(n)\n",
    "    svr_rbf = SVR(kernel=\"rbf\", C=70, gamma='auto', epsilon=0.4)\n",
    "    svr_rbf.fit(x_train, y_train.values.ravel())\n",
    "    print('test set')\n",
    "    model_metrics(svr_rbf, x_test, y_test, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eef29ecf-256c-4983-9725-bf5c340fb2a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set\n",
      "R^2: -0.004 +/- 0.003\n",
      "MAE: 3.02 +/- 0.07\n",
      "RMSE: 3.8 +/- 0.06\n",
      "test set\n",
      "R^2: -0.051 +/- 0.034\n",
      "MAE: 2.98 +/- 0.1\n",
      "RMSE: 3.82 +/- 0.12\n"
     ]
    }
   ],
   "source": [
    "svr_rbf = SVR(kernel=\"rbf\", C=70, gamma='auto', epsilon=0.4)\n",
    "svr_rbf.fit(x_train, y_train.values.ravel())\n",
    "print('training set')\n",
    "model_metrics(svr_rbf, x_train, y_train, cv=5)\n",
    "print('test set')\n",
    "model_metrics(svr_rbf, x_test, y_test, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0090771e-f3be-419c-b61c-f0665484aced",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "093ac33b-8899-44a4-9b95-16bb9aee8fef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set\n",
      "R^2: 0.429 +/- 0.049\n",
      "MAE: 2.1 +/- 0.07\n",
      "RMSE: 2.9 +/- 0.12\n",
      "test set\n",
      "R^2: 0.127 +/- 0.042\n",
      "MAE: 2.49 +/- 0.13\n",
      "RMSE: 3.3 +/- 0.11\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsRegressor(n_neighbors=4)\n",
    "knn.fit(x_train, y_train.values.ravel())\n",
    "print('training set')\n",
    "model_metrics(knn, x_train, y_train, cv=5)\n",
    "print('test set')\n",
    "model_metrics(knn, x_test, y_test, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a70b2662-2f0a-49ef-8dcc-571f976cd74b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "test set\n",
      "R^2: 0.266 +/- 0.039\n",
      "MAE: 2.29 +/- 0.09\n",
      "RMSE: 3.03 +/- 0.09\n",
      "9\n",
      "test set\n",
      "R^2: 0.279 +/- 0.039\n",
      "MAE: 2.27 +/- 0.11\n",
      "RMSE: 3.0 +/- 0.11\n",
      "10\n",
      "test set\n",
      "R^2: 0.292 +/- 0.034\n",
      "MAE: 2.24 +/- 0.12\n",
      "RMSE: 2.98 +/- 0.12\n",
      "11\n",
      "test set\n",
      "R^2: 0.305 +/- 0.029\n",
      "MAE: 2.25 +/- 0.12\n",
      "RMSE: 2.95 +/- 0.12\n",
      "12\n",
      "test set\n",
      "R^2: 0.274 +/- 0.025\n",
      "MAE: 2.28 +/- 0.11\n",
      "RMSE: 3.02 +/- 0.11\n"
     ]
    }
   ],
   "source": [
    "neighbors = [8, 9, 10, 11, 12]\n",
    "for n in neighbors:\n",
    "    print(n)\n",
    "    knn = KNeighborsRegressor(n_neighbors=n)\n",
    "    knn.fit(x_train, y_train.values.ravel())\n",
    "    print('test set')\n",
    "    model_metrics(knn, x_test, y_test, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ad7c7a2e-a7a8-47f8-b997-a7fe3e291ea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set\n",
      "R^2: 0.293 +/- 0.052\n",
      "MAE: 2.41 +/- 0.07\n",
      "RMSE: 3.18 +/- 0.13\n",
      "test set\n",
      "R^2: 0.229 +/- 0.03\n",
      "MAE: 2.58 +/- 0.09\n",
      "RMSE: 3.27 +/- 0.15\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsRegressor(n_neighbors=11)\n",
    "knn.fit(x_train, y_train.values.ravel())\n",
    "print('training set')\n",
    "model_metrics(knn, x_train, y_train, cv=5)\n",
    "print('test set')\n",
    "model_metrics(knn, x_test, y_test, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f29e88-2531-4095-b55f-742b920c6717",
   "metadata": {},
   "source": [
    "## lightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "94813c0c-2a04-40d9-b305-e214b7d512c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set\n",
      "R^2: 0.399 +/- 0.027\n",
      "MAE: 2.32 +/- 0.06\n",
      "RMSE: 2.98 +/- 0.07\n",
      "test set\n",
      "R^2: 0.18 +/- 0.028\n",
      "MAE: 2.48 +/- 0.08\n",
      "RMSE: 3.21 +/- 0.1\n"
     ]
    }
   ],
   "source": [
    "lgbm = LGBMRegressor(n_estimators=10, max_depth=5, num_leaves=2**5, learning_rate=0.1)\n",
    "lgbm.fit(x_train, y_train.values.ravel())\n",
    "print('training set')\n",
    "model_metrics(lgbm, x_train, y_train, cv=5)\n",
    "print('test set')\n",
    "model_metrics(lgbm, x_test, y_test, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "494ef4dd-0b13-4f55-8216-bb069b971307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01\n",
      "test set\n",
      "R^2: 0.023 +/- 0.006\n",
      "MAE: 2.72 +/- 0.1\n",
      "RMSE: 3.5 +/- 0.09\n",
      "0.1\n",
      "test set\n",
      "R^2: 0.184 +/- 0.025\n",
      "MAE: 2.47 +/- 0.08\n",
      "RMSE: 3.2 +/- 0.11\n",
      "0.5\n",
      "test set\n",
      "R^2: 0.125 +/- 0.022\n",
      "MAE: 2.57 +/- 0.09\n",
      "RMSE: 3.31 +/- 0.1\n"
     ]
    }
   ],
   "source": [
    "n_estimators=[10, 100, 500, 1000]\n",
    "max_depth = [3, 5, 7, 10]\n",
    "learning_rates = [0.01, 0.1, 0.5]\n",
    "for x in learning_rates:\n",
    "    print(x)\n",
    "    lgbm = LGBMRegressor(n_estimators=10, max_depth=3, num_leaves=2**3, learning_rate=0.1)\n",
    "    lgbm.fit(x_train, y_train.values.ravel())\n",
    "    print('test set')\n",
    "    model_metrics(lgbm, x_test, y_test, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cae35ab7-b733-49e5-86a2-474cd14f8449",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set\n",
      "R^2: 0.318 +/- 0.035\n",
      "MAE: 2.43 +/- 0.07\n",
      "RMSE: 3.13 +/- 0.1\n",
      "test set\n",
      "R^2: 0.221 +/- 0.028\n",
      "MAE: 2.67 +/- 0.09\n",
      "RMSE: 3.29 +/- 0.16\n"
     ]
    }
   ],
   "source": [
    "lgbm = LGBMRegressor(n_estimators=10, max_depth=3, num_leaves=2**3, learning_rate=0.1)\n",
    "lgbm.fit(x_train, y_train.values.ravel())\n",
    "print('training set')\n",
    "model_metrics(lgbm, x_train, y_train, cv=5)\n",
    "print('test set')\n",
    "model_metrics(lgbm, x_test, y_test, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8924f21b-d502-4cb1-8ead-df4551606011",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4a04a3-2062-4c22-ab71-666e7a188513",
   "metadata": {},
   "source": [
    "KNN performs the best with fingerprints and without. Let's see how the models improve by only training on PCE above 10 %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "4b344ffe-9255-4867-830f-eceb9e04f57d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#standardize\\nx_labels = X_unstandardized.columns\\nscaler = StandardScaler().fit(X_unstandardized[x_labels]) \\nX_unstandardized[x_labels] = scaler.transform(X_unstandardized[x_labels])\\n\\nfps = data_highPCE.iloc[:,64:]\\nX = pd.concat([X_unstandardized, fps], axis=1)'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_highPCE = data[data['PCE'] > 10]\n",
    "\n",
    "X = data_highPCE.iloc[:, 8:]\n",
    "y = data_highPCE.iloc[:, 7:8]\n",
    "'''\n",
    "#standardize\n",
    "x_labels = X_unstandardized.columns\n",
    "scaler = StandardScaler().fit(X_unstandardized[x_labels]) \n",
    "X_unstandardized[x_labels] = scaler.transform(X_unstandardized[x_labels])\n",
    "\n",
    "fps = data_highPCE.iloc[:,64:]\n",
    "X = pd.concat([X_unstandardized, fps], axis=1)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "b1f190f2-1f64-4f4f-93d3-a4c97b10bf78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into training and testing\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626ce3e8-ca03-40c4-b540-6320668137f9",
   "metadata": {},
   "source": [
    "### Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d600a324-88ad-448f-ae21-e4e4a52f4292",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha is 0.24628281421896436\n"
     ]
    }
   ],
   "source": [
    "lasso = LassoCV(cv=5, random_state=14, max_iter=10000)\n",
    "lasso.fit(x_train, y_train)\n",
    "print('Best alpha is ' + str(lasso.alpha_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "eb8f129c-bd44-4e13-95a6-5da71f735115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set\n",
      "R^2: 0.261 +/- 0.046\n",
      "MAE: 1.28 +/- 0.05\n",
      "RMSE: 1.61 +/- 0.05\n",
      "test set\n",
      "R^2: 0.134 +/- 0.114\n",
      "MAE: 1.34 +/- 0.14\n",
      "RMSE: 1.75 +/- 0.18\n"
     ]
    }
   ],
   "source": [
    "lasso = Lasso(alpha=0.246, random_state=14, max_iter=10000)\n",
    "lasso.fit(x_train, y_train)\n",
    "#print('Best alpha is ' + str(lasso.alpha_))\n",
    "\n",
    "print('training set')\n",
    "model_metrics(lasso, x_train, y_train, cv=5)\n",
    "print('test set')\n",
    "model_metrics(lasso, x_test, y_test, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c896bc-01b9-421f-93a8-5ee270b83b28",
   "metadata": {},
   "source": [
    "### RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "0b2abb13-244f-4498-ad41-a1c24149a5b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "test set\n",
      "R^2: 0.303 +/- 0.051\n",
      "MAE: 1.33 +/- 0.15\n",
      "RMSE: 1.61 +/- 0.19\n",
      "50\n",
      "test set\n",
      "R^2: 0.346 +/- 0.064\n",
      "MAE: 1.26 +/- 0.15\n",
      "RMSE: 1.56 +/- 0.19\n",
      "56\n",
      "test set\n",
      "R^2: 0.362 +/- 0.072\n",
      "MAE: 1.24 +/- 0.16\n",
      "RMSE: 1.54 +/- 0.2\n",
      "57\n",
      "test set\n",
      "R^2: 0.381 +/- 0.063\n",
      "MAE: 1.22 +/- 0.15\n",
      "RMSE: 1.52 +/- 0.2\n",
      "58\n",
      "test set\n",
      "R^2: 0.366 +/- 0.069\n",
      "MAE: 1.23 +/- 0.16\n",
      "RMSE: 1.54 +/- 0.2\n",
      "59\n",
      "test set\n",
      "R^2: 0.358 +/- 0.07\n",
      "MAE: 1.24 +/- 0.16\n",
      "RMSE: 1.55 +/- 0.2\n",
      "70\n",
      "test set\n",
      "R^2: 0.375 +/- 0.068\n",
      "MAE: 1.21 +/- 0.16\n",
      "RMSE: 1.53 +/- 0.2\n",
      "100\n",
      "test set\n",
      "R^2: 0.357 +/- 0.062\n",
      "MAE: 1.22 +/- 0.15\n",
      "RMSE: 1.55 +/- 0.19\n"
     ]
    }
   ],
   "source": [
    "n_estimators = [150, 200, 250, 300] \n",
    "max_depth = [5, 8, 10]\n",
    "min_samples_split = [2, 3]\n",
    "min_samples_leaf = [2, 4, 6]\n",
    "# max features had the biggest impact\n",
    "max_features = [30, 50, 56, 57, 58, 59, 70, 100]\n",
    "for x in max_features:\n",
    "    print(x)\n",
    "    rf = RandomForestRegressor(n_estimators=200,max_depth=8, min_samples_split=2, min_samples_leaf=2, max_features=57, random_state=20)\n",
    "    rf.fit(x_train, y_train)\n",
    "    print('test set')\n",
    "    model_metrics(rf, x_test, y_test, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "235eaa48-ec23-4243-8396-1542eeeff180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set\n",
      "R^2: 0.482 +/- 0.026\n",
      "MAE: 1.08 +/- 0.03\n",
      "RMSE: 1.35 +/- 0.04\n",
      "test set\n",
      "R^2: 0.381 +/- 0.063\n",
      "MAE: 1.22 +/- 0.15\n",
      "RMSE: 1.52 +/- 0.2\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestRegressor(n_estimators=200,max_depth=8, min_samples_split=2, min_samples_leaf=2, max_features=57, random_state=20)\n",
    "rf.fit(x_train, y_train)\n",
    "print('training set')\n",
    "model_metrics(rf, x_train, y_train, cv=5)\n",
    "print('test set')\n",
    "model_metrics(rf, x_test, y_test, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424bac34-9f3d-4644-b924-be03e18d4197",
   "metadata": {},
   "source": [
    "### GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "17247d10-f59e-4d37-93bd-aa7b4d2b9973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "test set\n",
      "R^2: 0.297 +/- 0.079\n",
      "MAE: 1.33 +/- 0.18\n",
      "RMSE: 1.62 +/- 0.21\n",
      "6\n",
      "test set\n",
      "R^2: 0.299 +/- 0.076\n",
      "MAE: 1.32 +/- 0.18\n",
      "RMSE: 1.62 +/- 0.21\n",
      "7\n",
      "test set\n",
      "R^2: 0.304 +/- 0.074\n",
      "MAE: 1.32 +/- 0.18\n",
      "RMSE: 1.61 +/- 0.21\n",
      "8\n",
      "test set\n",
      "R^2: 0.296 +/- 0.073\n",
      "MAE: 1.32 +/- 0.18\n",
      "RMSE: 1.62 +/- 0.21\n",
      "9\n",
      "test set\n",
      "R^2: 0.3 +/- 0.073\n",
      "MAE: 1.32 +/- 0.18\n",
      "RMSE: 1.62 +/- 0.21\n",
      "10\n",
      "test set\n",
      "R^2: 0.3 +/- 0.073\n",
      "MAE: 1.32 +/- 0.18\n",
      "RMSE: 1.62 +/- 0.21\n",
      "11\n",
      "test set\n",
      "R^2: 0.301 +/- 0.073\n",
      "MAE: 1.32 +/- 0.18\n",
      "RMSE: 1.61 +/- 0.21\n"
     ]
    }
   ],
   "source": [
    "n_estimators = [170, 180, 190, 200, 210, 220]\n",
    "subsample = [0.1, 0.2, 0.3]\n",
    "learning_rate = [0.02, 0.01, 0.03]\n",
    "max_depth = [5, 6, 7, 8 , 9, 10, 11]\n",
    "\n",
    "for x in max_depth:\n",
    "    print(x)\n",
    "    gb = GradientBoostingRegressor(learning_rate = 0.01, subsample = 0.2, n_estimators = 180, max_depth=7, random_state=22)\n",
    "    gb.fit(x_train, y_train.values.ravel())\n",
    "    print('test set')\n",
    "    model_metrics(gb, x_test, y_test, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "690f75bf-db3a-46b3-926e-919dd807af3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set\n",
      "R^2: 0.45 +/- 0.017\n",
      "MAE: 1.12 +/- 0.03\n",
      "RMSE: 1.39 +/- 0.04\n",
      "test set\n",
      "R^2: 0.304 +/- 0.074\n",
      "MAE: 1.32 +/- 0.18\n",
      "RMSE: 1.61 +/- 0.21\n"
     ]
    }
   ],
   "source": [
    "gb = GradientBoostingRegressor(learning_rate = 0.01, subsample = 0.2, n_estimators = 180, max_depth=7, random_state=22)\n",
    "gb.fit(x_train, y_train.values.ravel())\n",
    "print('training set')\n",
    "model_metrics(gb, x_train, y_train, cv=5)\n",
    "print('test set')\n",
    "model_metrics(gb, x_test, y_test, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9185f839-abdb-43b0-99b9-ff631f0e7124",
   "metadata": {},
   "source": [
    "### XGBRFR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "5cf15724-9b5e-464b-9d6a-a8bcfc663282",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03\n",
      "test set\n",
      "R^2: 0.328 +/- 0.072\n",
      "MAE: 1.23 +/- 0.15\n",
      "RMSE: 1.58 +/- 0.2\n",
      "0.04\n",
      "test set\n",
      "R^2: 0.349 +/- 0.081\n",
      "MAE: 1.22 +/- 0.15\n",
      "RMSE: 1.55 +/- 0.2\n",
      "0.05\n",
      "test set\n",
      "R^2: 0.318 +/- 0.071\n",
      "MAE: 1.25 +/- 0.14\n",
      "RMSE: 1.59 +/- 0.2\n",
      "0.001\n",
      "test set\n",
      "R^2: -0.097 +/- 0.06\n",
      "MAE: 1.68 +/- 0.15\n",
      "RMSE: 1.99 +/- 0.19\n",
      "0.1\n",
      "test set\n",
      "R^2: 0.31 +/- 0.066\n",
      "MAE: 1.26 +/- 0.15\n",
      "RMSE: 1.6 +/- 0.2\n"
     ]
    }
   ],
   "source": [
    "n_estimators = [10, 100, 500, 1000, 5000]\n",
    "subsample = [0.55, 0.6, 0.65, 0.8]\n",
    "colsample_bynode = [0.03, 0.04, 0.05, 0.001, 0.1]\n",
    "\n",
    "for x in colsample_bynode:\n",
    "    print(x)\n",
    "    xgbrfr = XGBRFRegressor(n_estimators=100, subsample=0.65, colsample_bynode=0.04, random_state=14)\n",
    "    xgbrfr.fit(x_train, y_train.values.ravel())\n",
    "    print('test set')\n",
    "    model_metrics(xgbrfr, x_test, y_test, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "eb47eba4-0acd-406f-b02f-443c8e9e666d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set\n",
      "R^2: 0.491 +/- 0.025\n",
      "MAE: 1.06 +/- 0.03\n",
      "RMSE: 1.33 +/- 0.04\n",
      "test set\n",
      "R^2: 0.349 +/- 0.081\n",
      "MAE: 1.22 +/- 0.15\n",
      "RMSE: 1.55 +/- 0.2\n"
     ]
    }
   ],
   "source": [
    "xgbrfr = XGBRFRegressor(n_estimators=100, subsample=0.65, colsample_bynode=0.04, random_state=14)\n",
    "xgbrfr.fit(x_train, y_train.values.ravel())\n",
    "print('training set')\n",
    "model_metrics(xgbrfr, x_train, y_train, cv=5)\n",
    "print('test set')\n",
    "model_metrics(xgbrfr, x_test, y_test, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c1fd821-3616-4c94-950e-a543c89b84fc",
   "metadata": {},
   "source": [
    "### SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "115f6da7-e34f-466a-85bf-21ac4d237bb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "test set\n",
      "R^2: 0.046 +/- 0.078\n",
      "MAE: 1.55 +/- 0.14\n",
      "RMSE: 1.85 +/- 0.2\n",
      "2\n",
      "test set\n",
      "R^2: -0.09 +/- 0.102\n",
      "MAE: 1.65 +/- 0.13\n",
      "RMSE: 1.95 +/- 0.16\n",
      "5\n",
      "test set\n",
      "R^2: -1.051 +/- 0.448\n",
      "MAE: 2.22 +/- 0.16\n",
      "RMSE: 2.54 +/- 0.14\n"
     ]
    }
   ],
   "source": [
    "C = [20, 65, 70, 75, 100]\n",
    "epsilon = [1, 2, 5]\n",
    "for x in epsilon:\n",
    "    print(x)\n",
    "    svr_rbf = SVR(kernel=\"rbf\", C=70, gamma='auto', epsilon=1)\n",
    "    svr_rbf.fit(x_train, y_train.values.ravel())\n",
    "    print('test set')\n",
    "    model_metrics(svr_rbf, x_test, y_test, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "91b36165-4224-45ca-bd40-85c8a1d01cd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set\n",
      "R^2: 0.145 +/- 0.05\n",
      "MAE: 1.38 +/- 0.04\n",
      "RMSE: 1.72 +/- 0.04\n",
      "test set\n",
      "R^2: 0.046 +/- 0.078\n",
      "MAE: 1.55 +/- 0.14\n",
      "RMSE: 1.85 +/- 0.2\n"
     ]
    }
   ],
   "source": [
    "svr_rbf = SVR(kernel=\"rbf\", C=70, gamma='auto', epsilon=1)\n",
    "svr_rbf.fit(x_train, y_train.values.ravel())\n",
    "print('training set')\n",
    "model_metrics(svr_rbf, x_train, y_train, cv=5)\n",
    "print('test set')\n",
    "model_metrics(svr_rbf, x_test, y_test, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4240f2dd-009d-45cc-bf47-9a025fcccf12",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "d4dd8b7b-f5ac-4f8e-ab93-1af6d6be3118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "test set\n",
      "R^2: 0.118 +/- 0.117\n",
      "MAE: 1.45 +/- 0.14\n",
      "RMSE: 1.75 +/- 0.17\n",
      "11\n",
      "test set\n",
      "R^2: 0.139 +/- 0.103\n",
      "MAE: 1.43 +/- 0.14\n",
      "RMSE: 1.74 +/- 0.16\n",
      "12\n",
      "test set\n",
      "R^2: 0.132 +/- 0.083\n",
      "MAE: 1.44 +/- 0.16\n",
      "RMSE: 1.76 +/- 0.17\n",
      "13\n",
      "test set\n",
      "R^2: 0.135 +/- 0.064\n",
      "MAE: 1.45 +/- 0.15\n",
      "RMSE: 1.76 +/- 0.16\n",
      "14\n",
      "test set\n",
      "R^2: 0.146 +/- 0.058\n",
      "MAE: 1.45 +/- 0.16\n",
      "RMSE: 1.75 +/- 0.17\n",
      "15\n",
      "test set\n",
      "R^2: 0.149 +/- 0.056\n",
      "MAE: 1.47 +/- 0.17\n",
      "RMSE: 1.76 +/- 0.18\n"
     ]
    }
   ],
   "source": [
    "neighbors = [10, 11, 12, 13, 14, 15]\n",
    "for n in neighbors:\n",
    "    print(n)\n",
    "    knn = KNeighborsRegressor(n_neighbors=n)\n",
    "    knn.fit(x_train, y_train.values.ravel())\n",
    "    print('test set')\n",
    "    model_metrics(knn, x_test, y_test, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "32216257-6fa4-4e9b-946e-8d867a294dd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set\n",
      "R^2: 0.246 +/- 0.071\n",
      "MAE: 1.26 +/- 0.02\n",
      "RMSE: 1.61 +/- 0.05\n",
      "test set\n",
      "R^2: 0.146 +/- 0.058\n",
      "MAE: 1.45 +/- 0.16\n",
      "RMSE: 1.75 +/- 0.17\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsRegressor(n_neighbors=14)\n",
    "knn.fit(x_train, y_train.values.ravel())\n",
    "print('training set')\n",
    "model_metrics(knn, x_train, y_train, cv=5)\n",
    "print('test set')\n",
    "model_metrics(knn, x_test, y_test, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5ccbd0-2ce8-4bdb-8a1a-c119810ab7b4",
   "metadata": {},
   "source": [
    "### lightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "d54b1426-13f4-4b47-a7fb-809219bb6564",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "test set\n",
      "R^2: 0.313 +/- 0.054\n",
      "MAE: 1.29 +/- 0.16\n",
      "RMSE: 1.59 +/- 0.18\n",
      "5\n",
      "test set\n",
      "R^2: 0.313 +/- 0.054\n",
      "MAE: 1.29 +/- 0.16\n",
      "RMSE: 1.59 +/- 0.18\n",
      "7\n",
      "test set\n",
      "R^2: 0.313 +/- 0.054\n",
      "MAE: 1.29 +/- 0.16\n",
      "RMSE: 1.59 +/- 0.18\n",
      "10\n",
      "test set\n",
      "R^2: 0.313 +/- 0.054\n",
      "MAE: 1.29 +/- 0.16\n",
      "RMSE: 1.59 +/- 0.18\n"
     ]
    }
   ],
   "source": [
    "n_estimators=[5, 10, 15, 20]\n",
    "max_depth = [3, 5, 7, 10]\n",
    "learning_rates = [0.15, 0.2, 0.25]\n",
    "for x in max_depth:\n",
    "    print(x)\n",
    "    lgbm = LGBMRegressor(n_estimators=15, max_depth=3, num_leaves=2**3, learning_rate=0.2)\n",
    "    lgbm.fit(x_train, y_train.values.ravel())\n",
    "    print('test set')\n",
    "    model_metrics(lgbm, x_test, y_test, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "2affe497-1d93-4ee0-a369-0ca77b5058d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set\n",
      "R^2: 0.444 +/- 0.02\n",
      "MAE: 1.1 +/- 0.02\n",
      "RMSE: 1.39 +/- 0.03\n",
      "test set\n",
      "R^2: 0.313 +/- 0.054\n",
      "MAE: 1.29 +/- 0.16\n",
      "RMSE: 1.59 +/- 0.18\n"
     ]
    }
   ],
   "source": [
    "lgbm = LGBMRegressor(n_estimators=15, max_depth=3, num_leaves=2**3, learning_rate=0.2)\n",
    "lgbm.fit(x_train, y_train.values.ravel())\n",
    "print('training set')\n",
    "model_metrics(lgbm, x_train, y_train, cv=5)\n",
    "print('test set')\n",
    "model_metrics(lgbm, x_test, y_test, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d246eb3e-fa1f-4786-9a70-01193266ab0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc61091e-48bb-44c6-8dcf-17aa1909568d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c96d9e4-8c34-4b19-b575-74bd7a4bcf01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d7e4fb40-f919-4484-a227-80e55e7c3ac5",
   "metadata": {},
   "source": [
    "# Performance of models with morgan fingerprints counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b23c55-b5fa-4ceb-a3af-ccb1fc44a0dc",
   "metadata": {},
   "source": [
    "We can add in morgan fingerprint counts and see if the performance improves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b52d456a-dbfa-4a6a-9f44-e2f46446e78d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of donor-acceptor pairs is: 999\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('descriptors_with_fingerprints_counts.csv')\n",
    "print('Number of donor-acceptor pairs is: ' + str(len(data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e564d42e-6636-4a2f-be1a-6624f24c9a92",
   "metadata": {},
   "source": [
    "Standardizes the descrptors (not including fingerprints) and then concats the fingerprints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "387d9c77-4852-48d6-9335-2d0be3ab28c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#standardize\\nx_labels = X_unstandardized.columns\\nscaler = StandardScaler().fit(X_unstandardized[x_labels]) \\nX_unstandardized[x_labels] = scaler.transform(X_unstandardized[x_labels])\\n\\nfps = data.iloc[:,64:]\\nX = pd.concat([X_unstandardized, fps], axis=1)'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data.iloc[:, 8:]\n",
    "y = data.iloc[:, 7:8]\n",
    "'''\n",
    "#standardize\n",
    "x_labels = X_unstandardized.columns\n",
    "scaler = StandardScaler().fit(X_unstandardized[x_labels]) \n",
    "X_unstandardized[x_labels] = scaler.transform(X_unstandardized[x_labels])\n",
    "\n",
    "fps = data.iloc[:,64:]\n",
    "X = pd.concat([X_unstandardized, fps], axis=1)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8e554c14-0a0f-421d-97a0-0d7c00d5a274",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into training and testing\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f87cd67-b749-4e8c-b684-1ae26e665a04",
   "metadata": {},
   "source": [
    "## Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e53dfb48-0606-41e7-9da7-8d9624639f4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set\n",
      "R^2: 0.381 +/- 0.045\n",
      "MAE: 2.33 +/- 0.09\n",
      "RMSE: 3.02 +/- 0.1\n",
      "test set\n",
      "R^2: -0.039 +/- 0.062\n",
      "MAE: 2.76 +/- 0.16\n",
      "RMSE: 3.61 +/- 0.18\n"
     ]
    }
   ],
   "source": [
    "lasso = Lasso(alpha=0.01, random_state=14, max_iter=10000)\n",
    "lasso.fit(x_train, y_train)\n",
    "#print('Best alpha is ' + str(lasso.alpha_))\n",
    "\n",
    "print('training set')\n",
    "model_metrics(lasso, x_train, y_train, cv=5)\n",
    "print('test set')\n",
    "model_metrics(lasso, x_test, y_test, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b82e5d3-b47c-41c9-8187-3ea93274f301",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0407c4b7-ff9c-4709-9954-db4f7c4ea642",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set\n",
      "R^2: 0.485 +/- 0.038\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-1bf2da664b97>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mrf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'training set'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mmodel_metrics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'test set'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mmodel_metrics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-2f99c9f6283f>\u001b[0m in \u001b[0;36mmodel_metrics\u001b[1;34m(model, X, y, cv)\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'R^2: '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr2\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' +/- '\u001b[0m \u001b[1;33m+\u001b[0m  \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSEM_r2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'neg_mean_absolute_error'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mSEM_MAE\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    438\u001b[0m     \u001b[0mscorer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_scoring\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    439\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 440\u001b[1;33m     cv_results = cross_validate(estimator=estimator, X=X, y=y, groups=groups,\n\u001b[0m\u001b[0;32m    441\u001b[0m                                 \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'score'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mscorer\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m                                 \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    244\u001b[0m     parallel = Parallel(n_jobs=n_jobs, verbose=verbose,\n\u001b[0;32m    245\u001b[0m                         pre_dispatch=pre_dispatch)\n\u001b[1;32m--> 246\u001b[1;33m     results = parallel(\n\u001b[0m\u001b[0;32m    247\u001b[0m         delayed(_fit_and_score)(\n\u001b[0;32m    248\u001b[0m             \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscorers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1042\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1043\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1044\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1045\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1046\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    857\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 859\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    860\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    775\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    776\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 777\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    778\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    220\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 222\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    591\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    592\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 593\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    594\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    595\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    385\u001b[0m             \u001b[1;31m# parallel_backend contexts set at a higher level,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    386\u001b[0m             \u001b[1;31m# since correctness does not rely on using threads.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 387\u001b[1;33m             trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n\u001b[0m\u001b[0;32m    388\u001b[0m                              \u001b[1;33m**\u001b[0m\u001b[0m_joblib_parallel_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprefer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'threads'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    389\u001b[0m                 delayed(_parallel_build_trees)(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1042\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1043\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1044\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1045\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1046\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    857\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 859\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    860\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    775\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    776\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 777\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    778\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    220\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 222\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[0;32m    167\u001b[0m                                                         indices=indices)\n\u001b[0;32m    168\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 169\u001b[1;33m         \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    170\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m         \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m   1245\u001b[0m         \"\"\"\n\u001b[0;32m   1246\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1247\u001b[1;33m         super().fit(\n\u001b[0m\u001b[0;32m   1248\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1249\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    387\u001b[0m                                            min_impurity_split)\n\u001b[0;32m    388\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 389\u001b[1;33m         \u001b[0mbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    390\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    391\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "rf = RandomForestRegressor(n_estimators=100,max_depth=30, min_samples_split=2, min_samples_leaf=2, max_features=17, random_state=14)\n",
    "rf.fit(x_train, y_train)\n",
    "print('training set')\n",
    "model_metrics(rf, x_train, y_train, cv=5)\n",
    "print('test set')\n",
    "model_metrics(rf, x_test, y_test, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9dac3a0-8491-47ed-8088-631168a78e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = [10, 100, 500, 1000] \n",
    "max_depth = [10, 30, 50, 100]\n",
    "min_samples_split = [2, 5, 7]\n",
    "min_samples_leaf = [2, 4, 6]\n",
    "# max features had the biggest impact\n",
    "max_features = [30, 40, 50, 60, 70]\n",
    "for x in max_features:\n",
    "    print(x)\n",
    "    rf = RandomForestRegressor(n_estimators=1000,max_depth=30, min_samples_split=2, min_samples_leaf=2, max_features=50, random_state=14)\n",
    "    rf.fit(x_train, y_train)\n",
    "    print('test set')\n",
    "    model_metrics(rf, x_test, y_test, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "60389377-90dc-4add-9df2-a0c52eb8972b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set\n",
      "R^2: 0.49 +/- 0.038\n",
      "MAE: 2.06 +/- 0.08\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-071eb85b365f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mrf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'training set'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mmodel_metrics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'test set'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mmodel_metrics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-2f99c9f6283f>\u001b[0m in \u001b[0;36mmodel_metrics\u001b[1;34m(model, X, y, cv)\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'MAE: '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMAE\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' +/- '\u001b[0m \u001b[1;33m+\u001b[0m  \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSEM_MAE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'neg_mean_squared_error'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m     \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscore\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0mSEM_RMSE\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    438\u001b[0m     \u001b[0mscorer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_scoring\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    439\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 440\u001b[1;33m     cv_results = cross_validate(estimator=estimator, X=X, y=y, groups=groups,\n\u001b[0m\u001b[0;32m    441\u001b[0m                                 \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'score'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mscorer\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m                                 \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    244\u001b[0m     parallel = Parallel(n_jobs=n_jobs, verbose=verbose,\n\u001b[0;32m    245\u001b[0m                         pre_dispatch=pre_dispatch)\n\u001b[1;32m--> 246\u001b[1;33m     results = parallel(\n\u001b[0m\u001b[0;32m    247\u001b[0m         delayed(_fit_and_score)(\n\u001b[0;32m    248\u001b[0m             \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscorers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1042\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1043\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1044\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1045\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1046\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    857\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 859\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    860\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    775\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    776\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 777\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    778\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    220\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 222\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    591\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    592\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 593\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    594\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    595\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    385\u001b[0m             \u001b[1;31m# parallel_backend contexts set at a higher level,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    386\u001b[0m             \u001b[1;31m# since correctness does not rely on using threads.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 387\u001b[1;33m             trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n\u001b[0m\u001b[0;32m    388\u001b[0m                              \u001b[1;33m**\u001b[0m\u001b[0m_joblib_parallel_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprefer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'threads'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    389\u001b[0m                 delayed(_parallel_build_trees)(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1042\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1043\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1044\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1045\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1046\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    857\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 859\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    860\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    775\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    776\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 777\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    778\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    220\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 222\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[0;32m    167\u001b[0m                                                         indices=indices)\n\u001b[0;32m    168\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 169\u001b[1;33m         \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    170\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m         \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m   1245\u001b[0m         \"\"\"\n\u001b[0;32m   1246\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1247\u001b[1;33m         super().fit(\n\u001b[0m\u001b[0;32m   1248\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1249\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    387\u001b[0m                                            min_impurity_split)\n\u001b[0;32m    388\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 389\u001b[1;33m         \u001b[0mbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    390\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    391\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "rf = RandomForestRegressor(n_estimators=1000,max_depth=30, min_samples_split=2, min_samples_leaf=2, max_features=50, random_state=14)\n",
    "rf.fit(x_train, y_train)\n",
    "print('training set')\n",
    "model_metrics(rf, x_train, y_train, cv=5)\n",
    "print('test set')\n",
    "model_metrics(rf, x_test, y_test, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984a698f-1049-4ba0-896b-f444639ae5d5",
   "metadata": {},
   "source": [
    "## Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0b00b640-b762-4793-9160-2737888c511c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set\n",
      "R^2: 0.531 +/- 0.04\n",
      "MAE: 1.93 +/- 0.08\n",
      "RMSE: 2.63 +/- 0.1\n",
      "test set\n",
      "R^2: 0.194 +/- 0.043\n",
      "MAE: 2.46 +/- 0.14\n",
      "RMSE: 3.18 +/- 0.15\n"
     ]
    }
   ],
   "source": [
    "gb = GradientBoostingRegressor(learning_rate = 0.02, subsample = 0.5, n_estimators = 1000, max_depth=6, random_state=14)\n",
    "\n",
    "gb.fit(x_train, y_train.values.ravel())\n",
    "print('training set')\n",
    "model_metrics(gb, x_train, y_train, cv=5)\n",
    "print('test set')\n",
    "model_metrics(gb, x_test, y_test, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "d4450d21-e22f-4c96-a2a7-b182a8dbc7e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "test set\n",
      "R^2: 0.232 +/- 0.035\n",
      "MAE: 2.39 +/- 0.13\n",
      "RMSE: 3.11 +/- 0.13\n",
      "12\n",
      "test set\n",
      "R^2: 0.254 +/- 0.026\n",
      "MAE: 2.35 +/- 0.12\n",
      "RMSE: 3.06 +/- 0.12\n",
      "13\n",
      "test set\n",
      "R^2: 0.224 +/- 0.038\n",
      "MAE: 2.39 +/- 0.13\n",
      "RMSE: 3.12 +/- 0.14\n",
      "14\n",
      "test set\n",
      "R^2: 0.232 +/- 0.035\n",
      "MAE: 2.38 +/- 0.13\n",
      "RMSE: 3.11 +/- 0.13\n",
      "15\n",
      "test set\n",
      "R^2: 0.232 +/- 0.035\n",
      "MAE: 2.38 +/- 0.13\n",
      "RMSE: 3.11 +/- 0.13\n"
     ]
    }
   ],
   "source": [
    "n_estimators = [90, 100, 110]\n",
    "subsample = [0.3, 0.5]\n",
    "learning_rate = [0.015, 0.02, 0.025]\n",
    "max_depth = [11, 12, 13, 14, 15]\n",
    "\n",
    "for x in max_depth:\n",
    "    print(x)\n",
    "    gb = GradientBoostingRegressor(learning_rate = 0.015, subsample = 0.3, n_estimators = 100, max_depth=12, random_state=14)\n",
    "    gb.fit(x_train, y_train.values.ravel())\n",
    "    print('test set')\n",
    "    model_metrics(gb, x_test, y_test, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e636adeb-0764-41cf-8a82-789157a94d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gb = GradientBoostingRegressor(learning_rate = 0.015, subsample = 0.3, n_estimators = 100, max_depth=12, random_state=14)\n",
    "gb.fit(x_train, y_train.values.ravel())\n",
    "print('training set')\n",
    "model_metrics(gb, x_train, y_train, cv=5)\n",
    "print('test set')\n",
    "model_metrics(gb, x_test, y_test, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2842c0a8-22d2-43ea-9bfa-0211bc6b277a",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ddb1b453-def9-4559-9286-b6904ec02296",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set\n",
      "R^2: 0.474 +/- 0.038\n",
      "MAE: 2.11 +/- 0.07\n",
      "RMSE: 2.79 +/- 0.09\n",
      "test set\n",
      "R^2: 0.255 +/- 0.02\n",
      "MAE: 2.33 +/- 0.1\n",
      "RMSE: 3.06 +/- 0.1\n"
     ]
    }
   ],
   "source": [
    "xgbrfr = XGBRFRegressor(n_estimators=1000, subsample=0.9, colsample_bynode=0.1, random_state=14)\n",
    "xgbrfr.fit(x_train, y_train.values.ravel())\n",
    "print('training set')\n",
    "model_metrics(xgbrfr, x_train, y_train, cv=5)\n",
    "print('test set')\n",
    "model_metrics(xgbrfr, x_test, y_test, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "3bad02fd-9d3b-4b60-8bdf-d3edbd761aec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03\n",
      "test set\n",
      "R^2: 0.283 +/- 0.018\n",
      "MAE: 2.29 +/- 0.11\n",
      "RMSE: 3.0 +/- 0.1\n",
      "0.02\n",
      "test set\n",
      "R^2: 0.277 +/- 0.02\n",
      "MAE: 2.29 +/- 0.1\n",
      "RMSE: 3.01 +/- 0.1\n",
      "0.04\n",
      "test set\n",
      "R^2: 0.283 +/- 0.019\n",
      "MAE: 2.29 +/- 0.1\n",
      "RMSE: 3.0 +/- 0.1\n"
     ]
    }
   ],
   "source": [
    "n_estimators = [10, 100, 500, 1000, 5000]\n",
    "subsample = [0.25, 0.3, 0.35]\n",
    "colsample_bynode = [0.03, 0.02, 0.04]\n",
    "\n",
    "for x in colsample_bynode:\n",
    "    print(x)\n",
    "    xgbrfr = XGBRFRegressor(n_estimators=500, subsample=0.35, colsample_bynode=0.03, random_state=14)\n",
    "    xgbrfr.fit(x_train, y_train.values.ravel())\n",
    "    print('test set')\n",
    "    model_metrics(xgbrfr, x_test, y_test, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20781407-a7df-4c57-be06-5e9fc733be21",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbrfr = XGBRFRegressor(n_estimators=500, subsample=0.35, colsample_bynode=0.03, random_state=14)\n",
    "xgbrfr.fit(x_train, y_train.values.ravel())\n",
    "print('training set')\n",
    "model_metrics(xgbrfr, x_train, y_train, cv=5)\n",
    "print('test set')\n",
    "model_metrics(xgbrfr, x_test, y_test, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c45690-ffbb-4adf-bf31-3b231a17fa6a",
   "metadata": {},
   "source": [
    "## SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3c9943bf-7dfa-40ac-bfa4-3fc1e449df17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set\n",
      "R^2: 0.279 +/- 0.031\n",
      "MAE: 2.53 +/- 0.05\n",
      "RMSE: 3.27 +/- 0.06\n",
      "test set\n",
      "R^2: 0.057 +/- 0.019\n",
      "MAE: 2.61 +/- 0.11\n",
      "RMSE: 3.44 +/- 0.1\n"
     ]
    }
   ],
   "source": [
    "svr_rbf = SVR(kernel=\"rbf\", C=1, gamma='auto', epsilon=0.1)\n",
    "svr_rbf.fit(x_train, y_train.values.ravel())\n",
    "print('training set')\n",
    "model_metrics(svr_rbf, x_train, y_train, cv=5)\n",
    "print('test set')\n",
    "model_metrics(svr_rbf, x_test, y_test, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "cf2e802a-35af-4684-8b17-997a5a2f3d89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.35\n",
      "test set\n",
      "R^2: 0.3 +/- 0.034\n",
      "MAE: 2.16 +/- 0.06\n",
      "RMSE: 2.96 +/- 0.09\n",
      "0.4\n",
      "test set\n",
      "R^2: 0.3 +/- 0.034\n",
      "MAE: 2.16 +/- 0.07\n",
      "RMSE: 2.96 +/- 0.09\n",
      "0.45\n",
      "test set\n",
      "R^2: 0.3 +/- 0.033\n",
      "MAE: 2.17 +/- 0.07\n",
      "RMSE: 2.96 +/- 0.09\n"
     ]
    }
   ],
   "source": [
    "C = [70, 60]\n",
    "epsilon = [0.35, 0.4, 0.45]\n",
    "for n in epsilon:\n",
    "    print(n)\n",
    "    svr_rbf = SVR(kernel=\"rbf\", C=70, gamma='auto', epsilon=0.4)\n",
    "    svr_rbf.fit(x_train, y_train.values.ravel())\n",
    "    print('test set')\n",
    "    model_metrics(svr_rbf, x_test, y_test, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd470b38-f39c-4074-ba3a-9006320d2728",
   "metadata": {},
   "outputs": [],
   "source": [
    "svr_rbf = SVR(kernel=\"rbf\", C=70, gamma='auto', epsilon=0.4)\n",
    "svr_rbf.fit(x_train, y_train.values.ravel())\n",
    "print('training set')\n",
    "model_metrics(svr_rbf, x_train, y_train, cv=5)\n",
    "print('test set')\n",
    "model_metrics(svr_rbf, x_test, y_test, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9898acbc-924e-441b-b271-1112281e984e",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6a563004-156b-4b79-abaa-1d43d6c2ab07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set\n",
      "R^2: 0.429 +/- 0.049\n",
      "MAE: 2.1 +/- 0.07\n",
      "RMSE: 2.9 +/- 0.12\n",
      "test set\n",
      "R^2: 0.127 +/- 0.042\n",
      "MAE: 2.49 +/- 0.13\n",
      "RMSE: 3.3 +/- 0.11\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsRegressor(n_neighbors=4)\n",
    "knn.fit(x_train, y_train.values.ravel())\n",
    "print('training set')\n",
    "model_metrics(knn, x_train, y_train, cv=5)\n",
    "print('test set')\n",
    "model_metrics(knn, x_test, y_test, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "460fba52-69b4-441c-b130-3de923734f73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "test set\n",
      "R^2: 0.266 +/- 0.039\n",
      "MAE: 2.29 +/- 0.09\n",
      "RMSE: 3.03 +/- 0.09\n",
      "9\n",
      "test set\n",
      "R^2: 0.279 +/- 0.039\n",
      "MAE: 2.27 +/- 0.11\n",
      "RMSE: 3.0 +/- 0.11\n",
      "10\n",
      "test set\n",
      "R^2: 0.292 +/- 0.034\n",
      "MAE: 2.24 +/- 0.12\n",
      "RMSE: 2.98 +/- 0.12\n",
      "11\n",
      "test set\n",
      "R^2: 0.305 +/- 0.029\n",
      "MAE: 2.25 +/- 0.12\n",
      "RMSE: 2.95 +/- 0.12\n",
      "12\n",
      "test set\n",
      "R^2: 0.274 +/- 0.025\n",
      "MAE: 2.28 +/- 0.11\n",
      "RMSE: 3.02 +/- 0.11\n"
     ]
    }
   ],
   "source": [
    "neighbors = [8, 9, 10, 11, 12]\n",
    "for n in neighbors:\n",
    "    print(n)\n",
    "    knn = KNeighborsRegressor(n_neighbors=n)\n",
    "    knn.fit(x_train, y_train.values.ravel())\n",
    "    print('test set')\n",
    "    model_metrics(knn, x_test, y_test, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8025b1d-4409-4271-82d2-3509ce471416",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsRegressor(n_neighbors=11)\n",
    "knn.fit(x_train, y_train.values.ravel())\n",
    "print('training set')\n",
    "model_metrics(knn, x_train, y_train, cv=5)\n",
    "print('test set')\n",
    "model_metrics(knn, x_test, y_test, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70144ea4-3cd6-48f2-95b6-df5ef5480b6a",
   "metadata": {},
   "source": [
    "## lightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4c18bb31-c6a0-49af-9cb5-51c0da450dc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set\n",
      "R^2: 0.399 +/- 0.027\n",
      "MAE: 2.32 +/- 0.06\n",
      "RMSE: 2.98 +/- 0.07\n",
      "test set\n",
      "R^2: 0.18 +/- 0.028\n",
      "MAE: 2.48 +/- 0.08\n",
      "RMSE: 3.21 +/- 0.1\n"
     ]
    }
   ],
   "source": [
    "lgbm = LGBMRegressor(n_estimators=10, max_depth=5, num_leaves=2**5, learning_rate=0.1)\n",
    "lgbm.fit(x_train, y_train.values.ravel())\n",
    "print('training set')\n",
    "model_metrics(lgbm, x_train, y_train, cv=5)\n",
    "print('test set')\n",
    "model_metrics(lgbm, x_test, y_test, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "353382ab-6025-468d-b8a7-0ad84a027770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01\n",
      "test set\n",
      "R^2: 0.023 +/- 0.006\n",
      "MAE: 2.72 +/- 0.1\n",
      "RMSE: 3.5 +/- 0.09\n",
      "0.1\n",
      "test set\n",
      "R^2: 0.184 +/- 0.025\n",
      "MAE: 2.47 +/- 0.08\n",
      "RMSE: 3.2 +/- 0.11\n",
      "0.5\n",
      "test set\n",
      "R^2: 0.125 +/- 0.022\n",
      "MAE: 2.57 +/- 0.09\n",
      "RMSE: 3.31 +/- 0.1\n"
     ]
    }
   ],
   "source": [
    "n_estimators=[10, 100, 500, 1000]\n",
    "max_depth = [3, 5, 7, 10]\n",
    "learning_rates = [0.01, 0.1, 0.5]\n",
    "for x in learning_rates:\n",
    "    print(x)\n",
    "    lgbm = LGBMRegressor(n_estimators=10, max_depth=3, num_leaves=2**3, learning_rate=0.1)\n",
    "    lgbm.fit(x_train, y_train.values.ravel())\n",
    "    print('test set')\n",
    "    model_metrics(lgbm, x_test, y_test, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1375f38-ff88-481e-b65b-df9548925dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm = LGBMRegressor(n_estimators=10, max_depth=3, num_leaves=2**3, learning_rate=0.1)\n",
    "lgbm.fit(x_train, y_train.values.ravel())\n",
    "print('training set')\n",
    "model_metrics(lgbm, x_train, y_train, cv=5)\n",
    "print('test set')\n",
    "model_metrics(lgbm, x_test, y_test, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3476fe3e-21e4-4a9c-a6df-86c0a4f8f611",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3acee135-812d-48de-b737-f0fcaebe7e02",
   "metadata": {},
   "source": [
    "KNN performs the best with fingerprints and without. Let's see how the models improve by only training on PCE above 10 %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6e4818da-efc9-4b11-bd04-a246e97a1e06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#standardize\\nx_labels = X_unstandardized.columns\\nscaler = StandardScaler().fit(X_unstandardized[x_labels]) \\nX_unstandardized[x_labels] = scaler.transform(X_unstandardized[x_labels])\\n\\nfps = data_highPCE.iloc[:,64:]\\nX = pd.concat([X_unstandardized, fps], axis=1)'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_highPCE = data[data['PCE'] > 10]\n",
    "\n",
    "X = data_highPCE.iloc[:, 8:]\n",
    "y = data_highPCE.iloc[:, 7:8]\n",
    "'''\n",
    "#standardize\n",
    "x_labels = X_unstandardized.columns\n",
    "scaler = StandardScaler().fit(X_unstandardized[x_labels]) \n",
    "X_unstandardized[x_labels] = scaler.transform(X_unstandardized[x_labels])\n",
    "\n",
    "fps = data_highPCE.iloc[:,64:]\n",
    "X = pd.concat([X_unstandardized, fps], axis=1)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6468de5c-b8e8-4ec3-9f9a-4809bd543fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into training and testing\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e577702a-e0e7-44fc-820d-92dfd16a2a5d",
   "metadata": {},
   "source": [
    "### Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cd9210eb-b395-4482-819e-1c52e1c2fe38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha is 0.24628281421896436\n"
     ]
    }
   ],
   "source": [
    "lasso = LassoCV(cv=5, random_state=14, max_iter=10000)\n",
    "lasso.fit(x_train, y_train)\n",
    "print('Best alpha is ' + str(lasso.alpha_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4ad37ba4-455b-42a7-8539-ac1d9d43070d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set\n",
      "R^2: 0.412 +/- 0.031\n",
      "MAE: 1.15 +/- 0.03\n",
      "RMSE: 1.43 +/- 0.04\n",
      "test set\n",
      "R^2: 0.172 +/- 0.128\n",
      "MAE: 1.3 +/- 0.16\n",
      "RMSE: 1.71 +/- 0.19\n"
     ]
    }
   ],
   "source": [
    "lasso = Lasso(alpha=0.246, random_state=14, max_iter=10000)\n",
    "lasso.fit(x_train, y_train)\n",
    "\n",
    "print('training set')\n",
    "model_metrics(lasso, x_train, y_train, cv=5)\n",
    "print('test set')\n",
    "model_metrics(lasso, x_test, y_test, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf9bc95-3bcb-4717-a9b5-e4f12e34283d",
   "metadata": {},
   "source": [
    "### RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f7a600a1-2ac0-40f4-abb4-12e2b85aa00a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "test set\n",
      "R^2: 0.319 +/- 0.065\n",
      "MAE: 1.3 +/- 0.16\n",
      "RMSE: 1.59 +/- 0.19\n",
      "50\n",
      "test set\n",
      "R^2: 0.35 +/- 0.059\n",
      "MAE: 1.25 +/- 0.16\n",
      "RMSE: 1.55 +/- 0.19\n",
      "56\n",
      "test set\n",
      "R^2: 0.384 +/- 0.06\n",
      "MAE: 1.22 +/- 0.16\n",
      "RMSE: 1.51 +/- 0.2\n",
      "57\n",
      "test set\n",
      "R^2: 0.394 +/- 0.073\n",
      "MAE: 1.2 +/- 0.16\n",
      "RMSE: 1.5 +/- 0.2\n",
      "58\n",
      "test set\n",
      "R^2: 0.366 +/- 0.067\n",
      "MAE: 1.23 +/- 0.17\n",
      "RMSE: 1.54 +/- 0.2\n",
      "59\n",
      "test set\n",
      "R^2: 0.367 +/- 0.083\n",
      "MAE: 1.22 +/- 0.16\n",
      "RMSE: 1.53 +/- 0.21\n",
      "70\n",
      "test set\n",
      "R^2: 0.357 +/- 0.067\n",
      "MAE: 1.23 +/- 0.15\n",
      "RMSE: 1.54 +/- 0.2\n",
      "100\n",
      "test set\n",
      "R^2: 0.36 +/- 0.071\n",
      "MAE: 1.23 +/- 0.16\n",
      "RMSE: 1.54 +/- 0.2\n"
     ]
    }
   ],
   "source": [
    "n_estimators = [60, 75, 90] \n",
    "max_depth = [5, 8, 10]\n",
    "min_samples_split = [2, 3]\n",
    "min_samples_leaf = [2, 4, 6]\n",
    "# max features had the biggest impact\n",
    "max_features = [30, 50, 56, 57, 58, 59, 70, 100]\n",
    "for x in max_features:\n",
    "    print(x)\n",
    "    rf = RandomForestRegressor(n_estimators=75,max_depth=8, min_samples_split=2, min_samples_leaf=2, max_features=57, random_state=20)\n",
    "    rf.fit(x_train, y_train)\n",
    "    print('test set')\n",
    "    model_metrics(rf, x_test, y_test, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6d9e0bf4-309a-4ed0-a707-0bb151fa3256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set\n",
      "R^2: 0.471 +/- 0.026\n",
      "MAE: 1.09 +/- 0.02\n",
      "RMSE: 1.36 +/- 0.03\n",
      "test set\n",
      "R^2: 0.394 +/- 0.073\n",
      "MAE: 1.2 +/- 0.16\n",
      "RMSE: 1.5 +/- 0.2\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestRegressor(n_estimators=75,max_depth=8, min_samples_split=2, min_samples_leaf=2, max_features=57, random_state=20)\n",
    "rf.fit(x_train, y_train)\n",
    "print('training set')\n",
    "model_metrics(rf, x_train, y_train, cv=5)\n",
    "print('test set')\n",
    "model_metrics(rf, x_test, y_test, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25fdfb1-8637-4b25-91ef-2157c42d8f28",
   "metadata": {},
   "source": [
    "### GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e76d286b-3365-4906-af0e-d14519598b49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "test set\n",
      "R^2: 0.349 +/- 0.078\n",
      "MAE: 1.26 +/- 0.17\n",
      "RMSE: 1.56 +/- 0.21\n",
      "6\n",
      "test set\n",
      "R^2: 0.348 +/- 0.075\n",
      "MAE: 1.26 +/- 0.17\n",
      "RMSE: 1.56 +/- 0.2\n",
      "7\n",
      "test set\n",
      "R^2: 0.346 +/- 0.073\n",
      "MAE: 1.27 +/- 0.17\n",
      "RMSE: 1.56 +/- 0.2\n",
      "8\n",
      "test set\n",
      "R^2: 0.351 +/- 0.074\n",
      "MAE: 1.26 +/- 0.17\n",
      "RMSE: 1.56 +/- 0.2\n",
      "9\n",
      "test set\n",
      "R^2: 0.348 +/- 0.074\n",
      "MAE: 1.26 +/- 0.17\n",
      "RMSE: 1.56 +/- 0.2\n",
      "10\n",
      "test set\n",
      "R^2: 0.348 +/- 0.074\n",
      "MAE: 1.26 +/- 0.17\n",
      "RMSE: 1.56 +/- 0.2\n",
      "11\n",
      "test set\n",
      "R^2: 0.348 +/- 0.074\n",
      "MAE: 1.26 +/- 0.17\n",
      "RMSE: 1.56 +/- 0.2\n"
     ]
    }
   ],
   "source": [
    "n_estimators = [200, 250, 300]\n",
    "subsample = [0.1, 0.2, 0.3]\n",
    "learning_rate = [0.02, 0.01, 0.03]\n",
    "max_depth = [5, 6, 7, 8, 9 , 10, 11]\n",
    "\n",
    "for x in max_depth:\n",
    "    print(x)\n",
    "    gb = GradientBoostingRegressor(learning_rate = 0.01, subsample =0.2, n_estimators = 200, max_depth=8, random_state=20)\n",
    "    gb.fit(x_train, y_train.values.ravel())\n",
    "    print('test set')\n",
    "    model_metrics(gb, x_test, y_test, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "feacaba3-d039-47f9-832c-09025615c733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set\n",
      "R^2: 0.45 +/- 0.023\n",
      "MAE: 1.11 +/- 0.03\n",
      "RMSE: 1.39 +/- 0.04\n",
      "test set\n",
      "R^2: 0.351 +/- 0.074\n",
      "MAE: 1.26 +/- 0.17\n",
      "RMSE: 1.56 +/- 0.2\n"
     ]
    }
   ],
   "source": [
    "gb = GradientBoostingRegressor(learning_rate = 0.01, subsample =0.2, n_estimators = 200, max_depth=8, random_state=20)\n",
    "gb.fit(x_train, y_train.values.ravel())\n",
    "print('training set')\n",
    "model_metrics(gb, x_train, y_train, cv=5)\n",
    "print('test set')\n",
    "model_metrics(gb, x_test, y_test, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00bdb12-57f1-4ab5-97ee-4270a5f83bda",
   "metadata": {},
   "source": [
    "### XGBRFR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "bbbbdca7-1ace-4db9-ba5d-fb227bfc4460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03\n",
      "test set\n",
      "R^2: 0.345 +/- 0.075\n",
      "MAE: 1.26 +/- 0.16\n",
      "RMSE: 1.56 +/- 0.21\n",
      "0.04\n",
      "test set\n",
      "R^2: 0.352 +/- 0.074\n",
      "MAE: 1.25 +/- 0.16\n",
      "RMSE: 1.56 +/- 0.21\n",
      "0.05\n",
      "test set\n",
      "R^2: 0.341 +/- 0.067\n",
      "MAE: 1.26 +/- 0.16\n",
      "RMSE: 1.57 +/- 0.21\n"
     ]
    }
   ],
   "source": [
    "n_estimators = [10, 100, 500, 1000]\n",
    "subsample = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6]\n",
    "colsample_bynode = [0.03, 0.04, 0.05]\n",
    "\n",
    "for x in colsample_bynode:\n",
    "    print(x)\n",
    "    xgbrfr = XGBRFRegressor(n_estimators=100, subsample=0.4, colsample_bynode=0.04, random_state=21)\n",
    "    xgbrfr.fit(x_train, y_train.values.ravel())\n",
    "    print('test set')\n",
    "    model_metrics(xgbrfr, x_test, y_test, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5e113072-3e70-4560-95f1-3758bad92bf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set\n",
      "R^2: 0.474 +/- 0.025\n",
      "MAE: 1.09 +/- 0.03\n",
      "RMSE: 1.36 +/- 0.04\n",
      "test set\n",
      "R^2: 0.352 +/- 0.074\n",
      "MAE: 1.25 +/- 0.16\n",
      "RMSE: 1.56 +/- 0.21\n"
     ]
    }
   ],
   "source": [
    "xgbrfr = XGBRFRegressor(n_estimators=100, subsample=0.4, colsample_bynode=0.04, random_state=21)\n",
    "xgbrfr.fit(x_train, y_train.values.ravel())\n",
    "print('training set')\n",
    "model_metrics(xgbrfr, x_train, y_train, cv=5)\n",
    "print('test set')\n",
    "model_metrics(xgbrfr, x_test, y_test, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80205ca-fcbc-49a1-adf7-8c92b220e7e8",
   "metadata": {},
   "source": [
    "### SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e829b2b1-3d0c-488a-b529-a8b82d2f8f5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001\n",
      "test set\n",
      "R^2: 0.065 +/- 0.116\n",
      "MAE: 1.52 +/- 0.16\n",
      "RMSE: 1.83 +/- 0.21\n",
      "0.01\n",
      "test set\n",
      "R^2: 0.065 +/- 0.116\n",
      "MAE: 1.52 +/- 0.16\n",
      "RMSE: 1.83 +/- 0.21\n",
      "0.1\n",
      "test set\n",
      "R^2: 0.067 +/- 0.114\n",
      "MAE: 1.52 +/- 0.17\n",
      "RMSE: 1.83 +/- 0.21\n",
      "1\n",
      "test set\n",
      "R^2: 0.054 +/- 0.077\n",
      "MAE: 1.55 +/- 0.15\n",
      "RMSE: 1.85 +/- 0.2\n"
     ]
    }
   ],
   "source": [
    "C = [1, 10, 15, 20]\n",
    "epsilon = [0.001, 0.01, 0.1, 1]\n",
    "for x in epsilon:\n",
    "    print(x)\n",
    "    svr_rbf = SVR(kernel=\"rbf\", C=1, gamma='auto', epsilon=0.1)\n",
    "    svr_rbf.fit(x_train, y_train.values.ravel())\n",
    "    print('test set')\n",
    "    model_metrics(svr_rbf, x_test, y_test, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1c66cb2b-e5da-4a0a-a703-fb0a051b5982",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set\n",
      "R^2: 0.182 +/- 0.032\n",
      "MAE: 1.29 +/- 0.04\n",
      "RMSE: 1.69 +/- 0.05\n",
      "test set\n",
      "R^2: 0.067 +/- 0.114\n",
      "MAE: 1.52 +/- 0.17\n",
      "RMSE: 1.83 +/- 0.21\n"
     ]
    }
   ],
   "source": [
    "svr_rbf = SVR(kernel=\"rbf\", C=1, gamma='auto', epsilon=0.1)\n",
    "svr_rbf.fit(x_train, y_train.values.ravel())\n",
    "print('training set')\n",
    "model_metrics(svr_rbf, x_train, y_train, cv=5)\n",
    "print('test set')\n",
    "model_metrics(svr_rbf, x_test, y_test, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99fc07d8-8281-42b1-807c-2f7a1817ac4b",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d50f2c56-a5db-4858-bca9-370067775166",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "test set\n",
      "R^2: -0.028 +/- 0.135\n",
      "MAE: 1.52 +/- 0.16\n",
      "RMSE: 1.91 +/- 0.2\n",
      "3\n",
      "test set\n",
      "R^2: 0.014 +/- 0.109\n",
      "MAE: 1.51 +/- 0.13\n",
      "RMSE: 1.86 +/- 0.17\n",
      "4\n",
      "test set\n",
      "R^2: 0.111 +/- 0.101\n",
      "MAE: 1.47 +/- 0.15\n",
      "RMSE: 1.78 +/- 0.17\n",
      "5\n",
      "test set\n",
      "R^2: 0.083 +/- 0.118\n",
      "MAE: 1.49 +/- 0.15\n",
      "RMSE: 1.79 +/- 0.17\n",
      "6\n",
      "test set\n",
      "R^2: 0.071 +/- 0.118\n",
      "MAE: 1.49 +/- 0.14\n",
      "RMSE: 1.79 +/- 0.16\n",
      "7\n",
      "test set\n",
      "R^2: 0.105 +/- 0.119\n",
      "MAE: 1.46 +/- 0.15\n",
      "RMSE: 1.76 +/- 0.16\n",
      "8\n",
      "test set\n",
      "R^2: 0.104 +/- 0.129\n",
      "MAE: 1.45 +/- 0.15\n",
      "RMSE: 1.76 +/- 0.17\n",
      "9\n",
      "test set\n",
      "R^2: 0.104 +/- 0.13\n",
      "MAE: 1.47 +/- 0.15\n",
      "RMSE: 1.76 +/- 0.18\n",
      "10\n",
      "test set\n",
      "R^2: 0.117 +/- 0.117\n",
      "MAE: 1.45 +/- 0.14\n",
      "RMSE: 1.75 +/- 0.17\n",
      "11\n",
      "test set\n",
      "R^2: 0.14 +/- 0.102\n",
      "MAE: 1.43 +/- 0.14\n",
      "RMSE: 1.74 +/- 0.16\n",
      "12\n",
      "test set\n",
      "R^2: 0.131 +/- 0.083\n",
      "MAE: 1.45 +/- 0.16\n",
      "RMSE: 1.76 +/- 0.17\n"
     ]
    }
   ],
   "source": [
    "neighbors = [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
    "for n in neighbors:\n",
    "    print(n)\n",
    "    knn = KNeighborsRegressor(n_neighbors=n)\n",
    "    knn.fit(x_train, y_train.values.ravel())\n",
    "    print('test set')\n",
    "    model_metrics(knn, x_test, y_test, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3663f495-aa61-41e3-a811-c0de5b77d772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set\n",
      "R^2: 0.25 +/- 0.073\n",
      "MAE: 1.26 +/- 0.03\n",
      "RMSE: 1.61 +/- 0.05\n",
      "test set\n",
      "R^2: 0.14 +/- 0.102\n",
      "MAE: 1.43 +/- 0.14\n",
      "RMSE: 1.74 +/- 0.16\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsRegressor(n_neighbors=11)\n",
    "knn.fit(x_train, y_train.values.ravel())\n",
    "print('training set')\n",
    "model_metrics(knn, x_train, y_train, cv=5)\n",
    "print('test set')\n",
    "model_metrics(knn, x_test, y_test, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e3fc8ac-0efc-4608-8e8b-c818944f98bf",
   "metadata": {},
   "source": [
    "### lightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c28c2d6a-e205-459e-9199-ad626839b389",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "test set\n",
      "R^2: 0.299 +/- 0.051\n",
      "MAE: 1.3 +/- 0.16\n",
      "RMSE: 1.61 +/- 0.19\n",
      "5\n",
      "test set\n",
      "R^2: 0.299 +/- 0.051\n",
      "MAE: 1.3 +/- 0.16\n",
      "RMSE: 1.61 +/- 0.19\n",
      "7\n",
      "test set\n",
      "R^2: 0.299 +/- 0.051\n",
      "MAE: 1.3 +/- 0.16\n",
      "RMSE: 1.61 +/- 0.19\n",
      "10\n",
      "test set\n",
      "R^2: 0.299 +/- 0.051\n",
      "MAE: 1.3 +/- 0.16\n",
      "RMSE: 1.61 +/- 0.19\n"
     ]
    }
   ],
   "source": [
    "n_estimators=[5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
    "max_depth = [3, 5, 7, 10]\n",
    "learning_rates = [0.15, 0.2, 0.25]\n",
    "for x in max_depth:\n",
    "    print(x)\n",
    "    lgbm = LGBMRegressor(n_estimators=12, max_depth=3, num_leaves=2**3, learning_rate=0.2)\n",
    "    lgbm.fit(x_train, y_train.values.ravel())\n",
    "    print('test set')\n",
    "    model_metrics(lgbm, x_test, y_test, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e8143d5e-804b-42ad-919f-347aab4b446e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set\n",
      "R^2: 0.449 +/- 0.022\n",
      "MAE: 1.09 +/- 0.02\n",
      "RMSE: 1.39 +/- 0.03\n",
      "test set\n",
      "R^2: 0.299 +/- 0.051\n",
      "MAE: 1.3 +/- 0.16\n",
      "RMSE: 1.61 +/- 0.19\n"
     ]
    }
   ],
   "source": [
    "lgbm = LGBMRegressor(n_estimators=12, max_depth=3, num_leaves=2**3, learning_rate=0.2)\n",
    "lgbm.fit(x_train, y_train.values.ravel())\n",
    "print('training set')\n",
    "model_metrics(lgbm, x_train, y_train, cv=5)\n",
    "print('test set')\n",
    "model_metrics(lgbm, x_test, y_test, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e913c1-7b29-43a0-bc28-354d25dbe1a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
